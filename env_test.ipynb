{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhh\\AppData\\Roaming\\Python\\Python39\\site-packages\\matplotlib\\projections\\__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import folium\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from h3 import h3\n",
    "from gym import spaces\n",
    "from folium.features import DivIcon\n",
    "from IPython.display import display\n",
    "from ride_hailing_match import Match\n",
    "from ride_hailing_location_model import Build_Model\n",
    "from pyproj import Transformer\n",
    "\n",
    "\n",
    "Global_Resolution = 6 # change the resolution here, determines the number of hexagonal cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is the source code to be modified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test cells below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Ride_hailing env\n",
    "This is the file for defining the simulator for the ride-hailing environment.\n",
    "Functions defined in this file can be used for reinforcement learning.\n",
    "This is part of the master thesis project:\n",
    "Optimising matching radius for a ride-hailing system.\n",
    "\n",
    "# Use this .py script:\n",
    "env = RideHailingENV()\n",
    "radius = env.reset()\n",
    "time_step = 1\n",
    "reward, next_state, matched_ride = env.step(radius, time_step, rend_step=False)\n",
    "\n",
    "# Test this environment for one step:\n",
    "env = RideHailingENV()\n",
    "radius = env.reset()\n",
    "time_step = 1\n",
    "reward, matched_ride = env.step(radius, time_step, rend_step=True)\n",
    "print(reward, matched_ride)\n",
    "\n",
    "# Test this environment for more steps:\n",
    "import random\n",
    "time_step += 1\n",
    "for i in range(np.size(radius)):\n",
    "    radius[i] = random.randint(50, 3000)\n",
    "reward, matched_ride = env.step(radius, time_step, rend_step=True)\n",
    "print(reward, matched_ride)\n",
    "\n",
    "# Test this environment for one episode (12 hours):\n",
    "import random\n",
    "radius = env.reset()\n",
    "time_step = 1\n",
    "import random\n",
    "for i in range(30*16):\n",
    "    time_step += 0\n",
    "    for i in range(np.size(radius)):\n",
    "        radius[i] = random.randint(50, 3000)\n",
    "    reward, matched_ride = env.step(radius, time_step, rend_step=False)\n",
    "print(reward, matched_ride)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import gym\n",
    "import folium\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from h3 import h3\n",
    "from gym import spaces\n",
    "from folium.features import DivIcon\n",
    "from IPython.display import display\n",
    "from ride_hailing_match import Match\n",
    "from ride_hailing_location_model import Build_Model\n",
    "from pyproj import Transformer\n",
    "\n",
    "\n",
    "Global_Resolution = 6 # change the resolution here, determines the number of hexagonal cells\n",
    "\n",
    "\n",
    "def wgs84_to_xy(x_arr: np.ndarray, y_arr: np.ndarray):\n",
    "    transformer = Transformer.from_crs('EPSG:4326', 'EPSG:32614')\n",
    "    x0 = 604082.94\n",
    "    y0 = 3328141.76\n",
    "    x_arr_new, y_arr_new = transformer.transform(x_arr, y_arr)\n",
    "    x_arr_new -= x0\n",
    "    y_arr_new -= y0\n",
    "    return x_arr_new.tolist(), y_arr_new.tolist()\n",
    "\n",
    "def xy_to_wgs84(xy_list):\n",
    "    transformer = Transformer.from_crs('EPSG:32614', 'EPSG:4326')\n",
    "    x_new = np.array(xy_list[0]) + 604082.94\n",
    "    y_new = np.array(xy_list[1]) + 3328141.76\n",
    "    lat_lon = transformer.transform(x_new, y_new)\n",
    "    return lat_lon\n",
    "\n",
    "def xy_to_wgs84_list(xy_list):\n",
    "    transformer = Transformer.from_crs('EPSG:32614', 'EPSG:4326')\n",
    "    x_arr = np.array(xy_list[0]) + 604082.94\n",
    "    y_arr = np.array(xy_list[1]) + 3328141.76\n",
    "    lat_list, lon_list = transformer.transform(x_arr, y_arr)\n",
    "    return lat_list.tolist(), lon_list.tolist()\n",
    "\n",
    "\n",
    "class HexH3:\n",
    "    \"\"\"Gennerate H3 hexagonal cells\n",
    "\n",
    "    This class is to gennerate hexagonal cells base on H3 package developed by Uber team.\n",
    "    The genenrated H3 cells are provided with a H3 code of each cell. In H3 defination, \n",
    "    each different cell has its unique H3 code, more information can be found on H3 official\n",
    "    website. This class is set default to gennerate H3 cells the urban area of Austin, Texas, USA.\n",
    "\n",
    "    Attributes:\n",
    "     lat_range - a tuple of latitude range, defines the location where H3 cells are gennerated\n",
    "     lon_range - a tuple of longitude range, defines the location where H3 cells are gennerated\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self.lat_range = [30.10, 30.54] # Austin latitude range\n",
    "        self.lon_range = [-97.96, -97.54] # Austin longitude range\n",
    "        pass\n",
    "   \n",
    "    def get_hexagons(self, resolution: int = 6, display_map: bool = False) -> list:\n",
    "        \"\"\"Gennerate H3 codes for studied area\n",
    "\n",
    "        Gennerate hexagonal codes and their H3 codes for the studied area,\n",
    "        with the package of H3 developed by Uber.\n",
    "\n",
    "        Parameters:\n",
    "         resolution - an int, with each the hexagonal cells will be generated.\n",
    "            This dedermines the number of the cells, the smaller this values is,\n",
    "            the more cells will be gennerated.\n",
    "         display - a bool, determines display the cells on the map or not.\n",
    "\n",
    "        Returns:\n",
    "         hexagons - a list, containing gennerated H3 codes for studied area.\n",
    "         m - a folium map, only return if argument display is set as True. This is a\n",
    "            map of studied area with gennerated cells and boundary.\n",
    "        \"\"\"\n",
    "        geoJson = {'type': 'Polygon',\n",
    "        'coordinates': [[[self.lat_range[0], self.lon_range[0]],\n",
    "                        [self.lat_range[0], self.lon_range[1]],\n",
    "                        [self.lat_range[1], self.lon_range[1]],\n",
    "                        [self.lat_range[1], self.lon_range[0]],\n",
    "                        ]] }\n",
    "\n",
    "        hexagons = np.array(list(h3.polyfill(geoJson, resolution)))\n",
    "\n",
    "        if not display_map:\n",
    "             return hexagons\n",
    "        else:\n",
    "            polyline = geoJson['coordinates'][0]\n",
    "            polyline.append(polyline[0])\n",
    "            lat = [p[0] for p in polyline]\n",
    "            lng = [p[1] for p in polyline]\n",
    "            m = folium.Map(location=[sum(lat)/len(lat), sum(lng)/len(lng)], zoom_start=12, tiles='cartodbpositron')\n",
    "            my_PolyLine=folium.PolyLine(locations=polyline,weight=8,color=\"green\")\n",
    "            m.add_child(my_PolyLine)\n",
    "            polylines = []\n",
    "            lat = []\n",
    "            lng = []\n",
    "            hex_id = 0\n",
    "            for hex in hexagons:\n",
    "                polygons = h3.h3_set_to_multi_polygon([str(hex)], geo_json=False)\n",
    "                # flatten polygons into loops.\n",
    "                outlines = [loop for polygon in polygons for loop in polygon]\n",
    "                polyline = [outline + [outline[0]] for outline in outlines][0]\n",
    "                lat_text = [p[0] for p in polyline]\n",
    "                lng_text = [p[1] for p in polyline]\n",
    "                folium.map.Marker(\n",
    "                    [sum(lat_text)/len(lat_text), sum(lng_text)/len(lng_text)-0.01],\n",
    "                    icon=DivIcon(\n",
    "                        icon_size=(250,36),\n",
    "                        icon_anchor=(0,0),\n",
    "                        html=f'<div style=\"font-size: 20pt\">{hex} hex_id:{hex_id}</div>',\n",
    "                        ) # print hex h3 code and corresponding hex id on the map\n",
    "                    ).add_to(m)\n",
    "                lat.extend(map(lambda v:v[0],polyline))\n",
    "                lng.extend(map(lambda v:v[1],polyline))\n",
    "                polylines.append(polyline)\n",
    "                hex_id +=1\n",
    "            for polyline in polylines:\n",
    "                my_PolyLine=folium.PolyLine(locations=polyline,weight=1,color='blue')\n",
    "                m.add_child(my_PolyLine)\n",
    "            display(m)\n",
    "\n",
    "            return hexagons\n",
    "        \n",
    "    def hex_h3_to_geo(self, hex_h3):\n",
    "        \"\"\"\n",
    "        Transform hex h3 code to geographical coordinates of six edge nodes.\n",
    "\n",
    "        Parameters:\n",
    "            hex_h3: a list of h3 codes, codes' type must be string.\n",
    "\n",
    "        Returns:\n",
    "            A pandas DataFrame including geographical information for hexagonal cells.\n",
    "        \"\"\"\n",
    "        hex_geo = pd.DataFrame(columns=['hex_id', 'hex_h3', 'east', 'north_east', 'north_west', 'south_east', 'south_west', 'west'])\n",
    "        for hex_id, hex_code in enumerate(hex_h3):\n",
    "            geo_info = list(h3.h3_to_geo_boundary(str(hex_code), geo_json=False))\n",
    "            hex_geo.loc[hex_id] = [hex_id, hex_code] + geo_info\n",
    "        return hex_geo\n",
    "        \n",
    "\n",
    "class Gen_Model:\n",
    "    \"\"\"Sample locations from fitted model for riders and drivers in the map\n",
    "\n",
    "    This class is to generate locations for riders and drivers based on the given\n",
    "    distribution of their locations. This default model is estimated with Kernel \n",
    "    Density Estimation (KDE). The generated location is given in the format of \n",
    "    a pandas DataFrame, each row represents a unique rider/driver. Information\n",
    "    given in a row includes rider/driver's ID, H3 code, longitude and latitude.\n",
    "\n",
    "    Attributes:\n",
    "        hexagons: a list of H3 codes of hexagon cells, indicating the studied area.\n",
    "        hexagons_dic: a dictionary, linking the local ID to its H3 code for H3 cells\n",
    "        model: an instance of Build_Model class containing models for riders and drivers\n",
    "        rider_model: a dictionary for 24 KDE distributions, describing the locational and timely distribution of riders\n",
    "        driver_model: a dictionary for 24 KDE distributions, describing the locational and timely distribution of drivers\n",
    "    \"\"\"\n",
    "    def __init__(self, resolution: int = Global_Resolution, random_seed = 1) -> None:\n",
    "        self.hex_h3 = HexH3()\n",
    "        self.hexagons = self.hex_h3.get_hexagons(resolution=resolution, display_map=False)\n",
    "        self.hexagons_dic = {h3_code: index for index, h3_code in enumerate(self.hexagons)}\n",
    "        self.model = Build_Model()\n",
    "        self.rider_model, self.driver_model = self.model.get_model()\n",
    "        self.random_seed = random_seed\n",
    "\n",
    "    def gen_drivers(self, number_of_drivers: int, hr_time: int, resolution: int = Global_Resolution):\n",
    "        \"\"\"Sample locations for drivers\n",
    "        \n",
    "        Sample multiple locations for drivers based on the given locational distribution \n",
    "        of drivers. The default distribution model is KDE.\n",
    "\n",
    "        Parameters:\n",
    "            number_of_drivers: an int, indicating how many drivers are generated.\n",
    "            hr_time: an int, the value is the hour of the day, indicating which distribution model will be used.\n",
    "            resolution: an int, determines the number of cells in the map.\n",
    "\n",
    "        Returns:\n",
    "            driver_df: a pandas DataFrame, including information of generated drivers. \n",
    "        \"\"\"\n",
    "        driver_locations = self.model.sample_from_model(self.driver_model[f'{hr_time}'], number_of_drivers, self.random_seed) # dtype = numpy ndarray\n",
    "        driver_ids = []\n",
    "        hex_ids = []\n",
    "\n",
    "        for driver_id, geo_info in enumerate(driver_locations):\n",
    "            hex_ids.append(self.hexagons_dic[h3.geo_to_h3(geo_info[0], geo_info[1], resolution)])\n",
    "            driver_ids.append(driver_id)\n",
    "\n",
    "        x_list, y_list = wgs84_to_xy(driver_locations.T[0], driver_locations.T[1])\n",
    "\n",
    "        driver_df = pd.DataFrame({'driver_id':driver_ids, 'hex_id':hex_ids, 'x':x_list, 'y':y_list})\n",
    "        # driver_df[['driver_id', 'hex_id']] = driver_df[['driver_id', 'hex_id']].astype(int) # set data type to int\n",
    "\n",
    "        return driver_df\n",
    "\n",
    "    def gen_riders(self, number_of_riders: int, hr_time: int, resolution: int = Global_Resolution):\n",
    "        \"\"\"Sample locations for riders\n",
    "        \n",
    "        Sample multiple locations for riders based on the given locational distribution \n",
    "        of riders. The default distribution model is KDE.\n",
    "\n",
    "        Parameters:\n",
    "            number_of_riders: an int, indicating how many riders are generated.\n",
    "            hr_time: an int, the value is the hour of the day, indicating which distribution model will be used.\n",
    "            resolution: an int, determines the number of cells in the map.\n",
    "\n",
    "        Returns:\n",
    "            rider_df: a pandas DataFrame, including information of generated riders. \n",
    "        \"\"\"\n",
    "        rider_locations = self.model.sample_from_model(self.rider_model[f'{hr_time}'], number_of_riders, self.random_seed) # dtype = numpy ndarray\n",
    "        rider_ids = []\n",
    "        hex_ids = []\n",
    "        \n",
    "        for rider_id, geo_info in enumerate(rider_locations):\n",
    "            hex_ids.append(self.hexagons_dic[h3.geo_to_h3(geo_info[0], geo_info[1], resolution)])\n",
    "            rider_ids.append(rider_id)\n",
    "\n",
    "        x_list, y_list = wgs84_to_xy(rider_locations.T[0], rider_locations.T[1])\n",
    "\n",
    "        rider_df = pd.DataFrame({'rider_id':rider_ids, 'hex_id':hex_ids, 'x':x_list, 'y':y_list, 'time_step_in_pool':0})\n",
    "        # rider_df[['rider_id', 'hex_id', 'time_step_in_pool']] = rider_df[['rider_id', 'hex_id', 'time_step_in_pool']].astype(int) # set data type to int\n",
    "\n",
    "        return rider_df\n",
    "\n",
    "\n",
    "class RideHailingENV(gym.Env):\n",
    "    \"\"\"Simulation environment for project optimising matching radius for ride-hailing system\n",
    "\n",
    "    This class is the main simulator for the master thesis project optimising matching radius \n",
    "    for a ride-hailing system with reinforcement learning. The project is carried out in TU Delft. \n",
    "    This simulator is built base on the geographical information of Austin, Texas, USA. It intake\n",
    "    continous matching radius as the action, and the reward is the total net profit made by the \n",
    "    system within a day.\n",
    "\n",
    "    Attributes:\n",
    "     lower_bound - lower bound of action space, minimum matching radius, unit is meters.\n",
    "     upper_bound - upper bound of action space, maximum matching radius, unit is meters.\n",
    "     hex_h3 - make an instance of HexH3 class, to generate hexagonal cells.\n",
    "     model - make an instance of Gen_Model class, to generate riders and drivers for the simulator.\n",
    "     match - make an instance of Match class, to run the matching algorithm.\n",
    "     hexagons - a list of hexagonal cells in the format of h3 codes, is index of hexagons.\n",
    "     num_cells - the number of hexagonal cells in the map, the scale of action space.\n",
    "     radius_initial - initial matching radius when reset the environment, unit is meters.\n",
    "     driver_num_ini - initial number of drivers, can be changed if set dynamic.\n",
    "     rider_num_ini - initial number of riders, rider number is changing among different steps.\n",
    "     fuel_unit_price - average travelling fuel cost per vehicle per kilometer in the US, the unit is US dollars.\n",
    "     time_window - time interval between every two matching process (Uber Batched matching), fixed among all steps, unit is minutes.\n",
    "     total_reward - total reward for the intake action.\n",
    "     gen_rate_rider - overall generating rate of riders, number of riders per time-window.\n",
    "     gen_rate_driver - active if vehicle number are set dynamic, number of new drivers per time-window.\n",
    "     ride_price - average ride price in Austin urban area, the value is estimated from Uber ride data in 2022.\n",
    "     rider_patience - the maximum number of steps a rider can stay in the matching pool.\n",
    "     p_unmatch_rider - penalty per unmatched rider, the value is cauculated base on the probability of losing a potential ride.\n",
    "     action_space - defines the numerical range of intake actions.\n",
    "     observation_space - defines the numerical range of overall observations.\n",
    "     sub_observation_space - defines the numerical range of observations within a cell.\n",
    "    \"\"\"\n",
    "    def __init__(self, random_seed: int = 1) -> None:\n",
    "\n",
    "        lower_bound = 50\n",
    "        upper_bound = 5000\n",
    "        self.hex_h3 = HexH3()\n",
    "        self.model = Gen_Model(random_seed=random_seed)\n",
    "        self.match = Match()\n",
    "        self.random_seed = random_seed\n",
    "\n",
    "        self.hexagons = self.hex_h3.get_hexagons(resolution=Global_Resolution, display_map=False)\n",
    "        self.hex_num = np.size(self.hexagons)\n",
    "        self.num_cells = np.size(self.hexagons)\n",
    "        self.radius_initial = 500\n",
    "        self.driver_num_ini = 100\n",
    "        self.rider_num_ini = 30\n",
    "        self.fuel_unit_price = 0.125 * 0.001 # per veh per kilomter -> per meter\n",
    "        self.time_window = 2\n",
    "        self.total_reward = 0\n",
    "        self.gen_rate_rider = 5\n",
    "        self.gen_rate_driver = 10\n",
    "        self.ride_price = 23.92\n",
    "        self.rider_patience = 5\n",
    "        self.p_unmatch_rider = self.ride_price / self.rider_patience\n",
    "\n",
    "        self.drivers = None\n",
    "        self.riders = None\n",
    "        self.drivers_tmp = None\n",
    "        self.riders_tmp = None\n",
    "\n",
    "        self.action_space = spaces.Box(\n",
    "                low=np.array(lower_bound*np.ones(self.num_cells)), \n",
    "                high=np.array(upper_bound*np.ones(self.num_cells)),\n",
    "                dtype=np.int32\n",
    "                )\n",
    "        self.observation_space = spaces.Discrete(self.num_cells*2)\n",
    "        self.sub_observation_space = spaces.Discrete(7)\n",
    "        \n",
    "    def reset(self, time_ini: int = 1) -> np.array:\n",
    "        \"\"\"\n",
    "        reset the environment for the first step in every episode.\n",
    "\n",
    "        Parameters:\n",
    "         time_ini -  set the initial time to 0-1 hour of a day.\n",
    "\n",
    "        Returns:\n",
    "         returns the initial matching radius.\n",
    "        \"\"\"\n",
    "        hexagons = self.hexagons\n",
    "        radius = np.ones_like(hexagons, dtype=int) * self.radius_initial\n",
    "        self.drivers = self.model.gen_drivers(self.driver_num_ini, time_ini)\n",
    "        self.riders = self.model.gen_riders(self.rider_num_ini, time_ini)\n",
    "\n",
    "        self.drivers['driver_id'] = np.arange(self.drivers.shape[0])\n",
    "        self.riders['rider_id'] = np.arange(self.riders.shape[0])\n",
    "\n",
    "        print(\"Simulator Initialized!\")\n",
    "        return radius\n",
    "    \n",
    "    def step(self, radius: np.array, hr_time: int, rend_step: bool = False) -> tuple[float, dict, list]:\n",
    "        \"\"\"\n",
    "        The main process of a step.\n",
    "\n",
    "        Parameters:\n",
    "         radius - matching radius for each cell.\n",
    "         hr_time - the hourly time step in a day, determines location distribution of riders and drivers.\n",
    "         rend_step - visualize one step if set to True.\n",
    "\n",
    "        Returns:\n",
    "         the reward of one step and matched pairs within this step. \n",
    "        \"\"\"\n",
    "\n",
    "        self.riders_tmp = self.riders.copy()\n",
    "        self.drivers_tmp = self.drivers.copy()\n",
    "\n",
    "        rider_vec = self.riders[['x', 'y']].values\n",
    "        driver_vec = self.drivers[['x', 'y']].values\n",
    "\n",
    "        # get the distance matrix and matching pool\n",
    "        dis_matrix = self.__vector_dis(rider_vec, driver_vec)\n",
    "        hex_ids = self.riders['hex_id']\n",
    "        r_radius = radius[hex_ids]\n",
    "\n",
    "        # get the matching pool\n",
    "        pool = self.__get_pool(dis_matrix, r_radius)\n",
    "\n",
    "        # matching process\n",
    "        match_statue = self.__match(pool)\n",
    "        reward = self.__execute_match(match_statue)\n",
    "        self.riders, self.drivers = self.__state_transit(hr_time)\n",
    "\n",
    "        if rend_step:\n",
    "            state = [self.riders_tmp, self.drivers_tmp]\n",
    "            self.render(state, radius, match_statue)\n",
    "        \n",
    "        return reward, match_statue\n",
    "    \n",
    "    def get_observe(self): # observation is number of riders/drivers in each cell\n",
    "        rider_counts = self.riders['hex_id'].value_counts().sort_index()\n",
    "        driver_counts = self.drivers['hex_id'].value_counts().sort_index()\n",
    "        rider_counts_list = rider_counts.reindex(range(self.hex_num), fill_value=0).tolist()\n",
    "        driver_counts_list = driver_counts.reindex(range(self.hex_num), fill_value=0).tolist()\n",
    "        return rider_counts_list, driver_counts_list\n",
    "    \n",
    "    def __get_pool(self, dis_matrix: list, radius_set: int) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        form a matching pool for all the riders and available drivers whithin the matching radius.\n",
    "\n",
    "        Parameters:\n",
    "            riders - locations, numbers of all the riders.\n",
    "            drivers - locations, numbers of all the drivers.\n",
    "            radius - matching radius for each cell, riders in the same cell have the same matching radius.\n",
    "\n",
    "        Returns:\n",
    "            returns a list consist all the possible matches and the distance between them.\n",
    "        \"\"\"\n",
    "        match_pool = []\n",
    "        for i in range(dis_matrix.shape[0]):\n",
    "            sub_pool = []\n",
    "            radius_rider = radius_set[i]\n",
    "            driver = list(np.where(dis_matrix[i] <= radius_rider)[1])\n",
    "            rider = list(np.ones(np.size(driver), dtype=int)*i)\n",
    "            dis = list(np.array(dis_matrix[i][dis_matrix[i] <= radius_rider])[0])\n",
    "            sub_pool.extend([rider])\n",
    "            sub_pool.extend([driver])\n",
    "            sub_pool.extend([dis])\n",
    "            sub_pool = list(map(list, zip(*sub_pool)))\n",
    "            match_pool.extend(sub_pool)\n",
    "        return match_pool\n",
    "            \n",
    "    def __match(self, pool: list): # MM: Maximum Matching, OM: Optimised Matching\n",
    "        \"\"\"\n",
    "        excute matching algorithm to find the optimal match for the given matching pool.\n",
    "\n",
    "        Parameters:\n",
    "         pool - matching pool with distance. \n",
    "\n",
    "        Returns:\n",
    "         match statue with matched pairs and their distance. \n",
    "        \"\"\"\n",
    "        matched_pairs = self.match.match(pool, method='Munkres')\n",
    "        return matched_pairs\n",
    "    \n",
    "    def __execute_match(self, match_statue:list) -> tuple[float, tuple]:\n",
    "        \"\"\"\n",
    "        apply the matched pairs to the map, update riders and drivers, observe reward and penalty.\n",
    "\n",
    "        Parameters:\n",
    "         riders - locations, numbers of all the riders.\n",
    "         drivers - locations, numbers of all the drivers.\n",
    "         match_statue - matched pair of riders and drivers with the distance between them.\n",
    "\n",
    "        Returns:\n",
    "         reward - the net monetary profit made from the ride-hailing system within a step.\n",
    "         pool_next - next state of the environment after taking the action.\n",
    "        \"\"\"\n",
    "        # initialise some variables\n",
    "        reward = 0\n",
    "        dis = 0\n",
    "\n",
    "        # iterate over matched pairs\n",
    "        for rider, driver, distance in match_statue:\n",
    "            self.riders = self.riders.drop(rider)\n",
    "            self.drivers = self.drivers.drop(driver)\n",
    "            dis += distance\n",
    "            reward += self.ride_price\n",
    "\n",
    "        # calculate punishment and travel cost, finish the reward function\n",
    "        reward -= dis * self.fuel_unit_price + self.p_unmatch_rider * len(self.riders) + self.fuel_unit_price * len(self.drivers)\n",
    "\n",
    "        return reward\n",
    "    \n",
    "    def __vector_dis(self, rider_vec, driver_vec):\n",
    "        m = np.shape(rider_vec)[0]\n",
    "        n = np.shape(driver_vec)[0]\n",
    "        M = np.dot(rider_vec, driver_vec.T)\n",
    "        H = np.tile(np.matrix(np.square(rider_vec).sum(axis=1)).T,(1,n))\n",
    "        K = np.tile(np.matrix(np.square(driver_vec).sum(axis=1)),(m,1))\n",
    "        return np.sqrt(-2 * M + H + K)\n",
    "    \n",
    "    def __state_transit(self, hr_time: int) -> dict: \n",
    "        \"\"\"\n",
    "        update the current state and give the state of the next step.\n",
    "\n",
    "        Parameters:\n",
    "         state - the current state, locations of riders and drivers.\n",
    "         hr_time - hourly time of a day, this is used to generate new riders and drivers.\n",
    "\n",
    "        Returns:\n",
    "         returns the locations of riders and drivers for the next step.\n",
    "        \"\"\"\n",
    "\n",
    "        # update riders\n",
    "        rider_size = self.gen_rate_rider * self.time_window\n",
    "        new_riders = self.model.gen_riders(rider_size, hr_time)\n",
    "        rider_next = pd.concat((self.riders, new_riders), axis=0)\n",
    "        rider_next['time_step_in_pool'] += 1\n",
    "        rider_next = rider_next.drop(rider_next[rider_next['time_step_in_pool']>self.rider_patience].index) # inpatient riders quit the matching pool\n",
    "\n",
    "        # update drivers\n",
    "        driver_size = self.driver_num_ini\n",
    "        driver_next = self.model.gen_drivers(driver_size, hr_time)\n",
    "\n",
    "        rider_next = rider_next.reset_index(drop=True)\n",
    "        driver_next = driver_next.reset_index(drop=True)\n",
    "\n",
    "        # re-index drivers and riders\n",
    "        driver_index = driver_next.shape[0]\n",
    "        driver_next['driver_id'] = np.arange(driver_index)\n",
    "        rider_index = rider_next.shape[0]\n",
    "        rider_next['rider_id'] = np.arange(rider_index)\n",
    "\n",
    "        return rider_next, driver_next\n",
    "\n",
    "    def render(self, state: tuple, radius_set: dict, match_statue: list, color_set: tuple = ['red', 'blue'], folium_map=None) -> None:\n",
    "        \"\"\"\n",
    "        visualise the state and action for one step, red circle is matching range (within matching radius),\n",
    "        green lines are the links for matched pairs.\n",
    "\n",
    "        Parameters:\n",
    "         state - the current state, locations of riders and drivers.\n",
    "         radius_set - matching radius for each cell.\n",
    "         match_statue - matched pair of riders and drivers with the distance between them.\n",
    "         color_set - the color for matching radius and hexagonal cells respectively.\n",
    "         folium_map - map object.\n",
    "        \"\"\"\n",
    "\n",
    "        cells = self.hexagons\n",
    "        riders = state[0]\n",
    "        drivers = state[1]\n",
    "\n",
    "        matched_riders = pd.DataFrame(match_statue)[0].to_list()\n",
    "        matched_drivers = pd.DataFrame(match_statue)[1].to_list()\n",
    "        polylines = []\n",
    "        lat = []\n",
    "        lng = []\n",
    "        matched_rider_location = {}\n",
    "        matched_driver_location = {}\n",
    "\n",
    "        for cell in cells:\n",
    "            cell = str(cell)\n",
    "            polygons = h3.h3_set_to_multi_polygon([cell], geo_json=False)\n",
    "            outlines = [loop for polygon in polygons for loop in polygon]\n",
    "            polyline = [outline + [outline[0]] for outline in outlines][0]\n",
    "            lat.extend(map(lambda v:v[0],polyline))\n",
    "            lng.extend(map(lambda v:v[1],polyline))\n",
    "            polylines.append(polyline)\n",
    "        if folium_map is None:\n",
    "            m = folium.Map(location=[sum(lat)/len(lat), sum(lng)/len(lng)], zoom_start=12, tiles='openstreetmap') # titles can also be: 'cartodbpositron'\n",
    "        else:\n",
    "            m = folium_map\n",
    "        for polyline in polylines:\n",
    "            my_PolyLine=folium.PolyLine(locations=polyline,weight=2,color='blue')\n",
    "            m.add_child(my_PolyLine)\n",
    "       \n",
    "        # add driver markers\n",
    "        for i in range(drivers.shape[0]):\n",
    "            driver_wgs = xy_to_wgs84([drivers.loc[i]['x'], drivers.loc[i]['y']])\n",
    "            folium.Marker(\n",
    "                location=driver_wgs,\n",
    "                icon=folium.Icon(\n",
    "                    color=color_set[0],\n",
    "                    prefix='fa',\n",
    "                    icon='car'\n",
    "                    )\n",
    "                ).add_to(m)\n",
    "            if drivers.loc[i]['driver_id'] in matched_drivers:\n",
    "                matched_driver_location[f'{int(drivers.loc[i][\"driver_id\"])}'] = driver_wgs\n",
    "          \n",
    "        # add rider markers and matching radius\n",
    "        for j in range(riders.shape[0]):\n",
    "            rider_wgs = xy_to_wgs84([riders.loc[j]['x'], riders.loc[j]['y']])\n",
    "            folium.Marker(\n",
    "                location=rider_wgs,\n",
    "                icon=folium.Icon(\n",
    "                    color=color_set[1],\n",
    "                    prefix='fa',\n",
    "                    icon='male'\n",
    "                    )\n",
    "                ).add_to(m)\n",
    "            \n",
    "            folium.Circle(\n",
    "                    radius=float(radius_set[int(riders.loc[j]['hex_id'])]),\n",
    "                    location=rider_wgs,\n",
    "                    color=\"red\",\n",
    "                    weight=1,\n",
    "                    fill=True,\n",
    "                    fill_opacity=0.1\n",
    "                ).add_to(m)\n",
    "            if riders.loc[j]['rider_id'] in matched_riders:\n",
    "                matched_rider_location[f'{int(riders.loc[j][\"rider_id\"])}'] = rider_wgs\n",
    "       \n",
    "        for rider, driver, dis in match_statue:\n",
    "            folium.PolyLine(\n",
    "                locations=[matched_rider_location[f'{int(rider)}'], matched_driver_location[f'{int(driver)}']],\n",
    "                color='green', \n",
    "                weight=5,\n",
    "                tooltip='matched_links'\n",
    "                ).add_to(m)\n",
    "    \n",
    "        display(m)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulator Initialized!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "       500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "       500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "       500, 500, 500, 500, 500, 500, 500, 500, 500])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = RideHailingENV(random_seed=1)\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>driver_id</th>\n",
       "      <th>hex_id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>18299.000053</td>\n",
       "      <td>26579.354418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>16743.187196</td>\n",
       "      <td>19227.040267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>17478.524612</td>\n",
       "      <td>20329.953486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>3019.685036</td>\n",
       "      <td>9585.007035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>20092.202976</td>\n",
       "      <td>25441.125854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>27</td>\n",
       "      <td>15218.351255</td>\n",
       "      <td>20600.317765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>21</td>\n",
       "      <td>19493.978535</td>\n",
       "      <td>22923.082396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>27</td>\n",
       "      <td>16200.322083</td>\n",
       "      <td>20777.177236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>27</td>\n",
       "      <td>16382.388597</td>\n",
       "      <td>21439.591639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>27</td>\n",
       "      <td>17000.993140</td>\n",
       "      <td>23744.112390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    driver_id  hex_id             x             y\n",
       "0           0      12  18299.000053  26579.354418\n",
       "1           1      26  16743.187196  19227.040267\n",
       "2           2      27  17478.524612  20329.953486\n",
       "3           3      38   3019.685036   9585.007035\n",
       "4           4      21  20092.202976  25441.125854\n",
       "..        ...     ...           ...           ...\n",
       "95         95      27  15218.351255  20600.317765\n",
       "96         96      21  19493.978535  22923.082396\n",
       "97         97      27  16200.322083  20777.177236\n",
       "98         98      27  16382.388597  21439.591639\n",
       "99         99      27  17000.993140  23744.112390\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Gen_Model()\n",
    "d = model.gen_drivers(100, 1)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hex = HexH3()\n",
    "h = hex.get_hexagons()\n",
    "print(np.size(h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建示例 DataFrame\n",
    "data = {'A': np.random.randint(0, 49, size=100),\n",
    "        'B': np.random.randint(0, 49, size=100)}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 统计 'A' 列元素出现的次数\n",
    "counts = df['A'].value_counts().sort_index()\n",
    "\n",
    "# 使用 reindex 方法构建列表\n",
    "result_list = counts.reindex(range(49), fill_value=0).tolist()\n",
    "\n",
    "print(data['A'],result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = RideHailingENV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.observation_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.action_space.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import folium\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from folium.plugins import HeatMap\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "\n",
    "class Dataset_Info:\n",
    "    def show_heatmap(coord_data, keyword='start_location', zoom=9, data_format='dataframe'):\n",
    "        m = folium.Map(location=(30.2672, -97.7431), zoom_start=zoom)\n",
    "        if data_format == 'dataframe':\n",
    "            data = list(coord_data.groupby([f'{keyword}_lat', f'{keyword}_long']).groups.keys())\n",
    "        if data_format == 'ndarray':\n",
    "            data = coord_data\n",
    "        heatmap = HeatMap(data, radius=14)\n",
    "        heatmap.add_to(m)\n",
    "\n",
    "        return m\n",
    "\n",
    "    def draw_hist(data, title):\n",
    "        plt.figure(figsize=(15,2))\n",
    "        plt.hist(data, density=True, bins=500) \n",
    "        plt.ylabel('Probability')\n",
    "        plt.xlabel('Data')\n",
    "        plt.title(title)\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "\n",
    "        pass\n",
    "\n",
    "    def draw_scatter(data, keyword, title, sample_plot=True, sample_scale=1000, get_sample=False):\n",
    "        fig = plt.figure(figsize=(10,7))\n",
    "        if sample_plot == True:\n",
    "            sample_idx = np.random.choice(data.shape[0], sample_scale, replace=False)\n",
    "            sampled_reverse = data.loc[sample_idx]\n",
    "            sampled_data = sampled_reverse[[f'{keyword}_lat', f'{keyword}_long']]\n",
    "            plt.scatter(sampled_data[f'{keyword}_lat'], sampled_data[f'{keyword}_long'], alpha=0.7)\n",
    "        else:\n",
    "            plt.scatter(data[f'{keyword}_lat'], data[f'{keyword}_long'], alpha=0.7)\n",
    "        plt.ylabel('Probability')\n",
    "        plt.xlabel('Data')\n",
    "        plt.title(title)\n",
    "        plt.grid() \n",
    "        plt.show()\n",
    "\n",
    "        if get_sample == True:\n",
    "            return sampled_data\n",
    "\n",
    "\n",
    "class Build_Model:\n",
    "    def __init__(self) -> None:\n",
    "        self.rider_dataset_hr = pd.read_csv('./dataset/rider_data_hr.csv')\n",
    "        self.driver_dataset_hr = pd.read_csv('./dataset/driver_data_hr.csv')\n",
    "        self.lat_range = [30.16, 30.49] # location gennerating range\n",
    "        self.lon_range = [-97.90, -97.61] # location gennerating range\n",
    "\n",
    "        pass\n",
    "    \n",
    "    def data_slice(self):\n",
    "        start_loc = self.dataset[[\"RIDE_ID\", \"started_on\", \"start_location_lat\", \"start_location_long\"]]\n",
    "        end_loc = self.dataset[[\"RIDE_ID\", \"completed_on\", \"end_location_lat\", \"end_location_long\"]]\n",
    "\n",
    "        return start_loc, end_loc\n",
    "    \n",
    "    def data_filter(self):\n",
    "        data = self.dataset\n",
    "        lat_range = self.lat_range # location gennerating range\n",
    "        lon_range = self.lon_range # location gennerating range\n",
    "        data = data.drop(data[(data['start_location_lat']<lat_range[0]) | (data['start_location_lat']>lat_range[1])].index)\n",
    "        data = data.drop(data[(data['start_location_long']<lon_range[0]) | (data['start_location_long']>lon_range[1])].index)\n",
    "        data = data.drop(data[(data['end_location_lat']<lat_range[0]) | (data['end_location_lat']>lat_range[1])].index)\n",
    "        data = data.drop(data[(data['end_location_long']<lon_range[0]) | (data['end_location_long']>lon_range[1])].index)\n",
    "        start_loc, end_loc = self.data_slice()\n",
    "        rider_dataset_hr = self.add_step_info(start_loc, keyword='started_on', step_size=60)\n",
    "        driver_dataset_hr = self.add_step_info(end_loc, keyword='completed_on', step_size=60)\n",
    "        rider_dataset_hr.to_csv('../dataset/rider_data_hr.csv')\n",
    "        driver_dataset_hr.to_csv('../dataset/driver_data_hr.csv')\n",
    "\n",
    "        pass\n",
    "\n",
    "    def add_step_info(self, data, keyword, step_size=60):\n",
    "        # keyword: which column contains time data, step_size: how many minuetes per time step\n",
    "        step_dataset = data.copy()\n",
    "        step_dataset[f'{keyword}'] = pd.to_datetime(step_dataset[f'{keyword}'])\n",
    "        step_dataset[f'{keyword}'] = step_dataset[f'{keyword}'].dt.time\n",
    "        step_dataset.insert(step_dataset.shape[1], 'time_step_index', 1)\n",
    "        number_step = int(1440 / step_size)\n",
    "\n",
    "        start_time = datetime.datetime.strptime('00:00:00', '%H:%M:%S')\n",
    "        time_debug = datetime.datetime.strptime('1900-01-02 00:00:00', '%Y-%m-%d %H:%M:%S') - datetime.timedelta(minutes=step_size)\n",
    "\n",
    "        for i in range(number_step):\n",
    "            if start_time == time_debug:\n",
    "                end_time = start_time + datetime.timedelta(minutes=step_size) - datetime.timedelta(seconds=1)\n",
    "            else:\n",
    "                end_time = start_time + datetime.timedelta(minutes=step_size)\n",
    "            start_time_f = start_time.time()\n",
    "            end_time_f = end_time.time()\n",
    "            step_index = i + 1\n",
    "            step_dataset.loc[(step_dataset[f'{keyword}'] > start_time_f) & (step_dataset[f'{keyword}'] <= end_time_f), 'time_step_index'] = step_index\n",
    "            start_time = datetime.datetime.strptime(str(end_time_f), '%H:%M:%S')\n",
    "\n",
    "        return step_dataset\n",
    "\n",
    "    def sample_from_model(self, model: object, num_sample: int = 1000, seed = 1) -> list:\n",
    "        sample = model.sample(num_sample, random_state=seed)\n",
    "        #sample_df = pd.DataFrame(sample, columns=['sampled_location_lat', 'sampled_location_long'])\n",
    "\n",
    "        return sample\n",
    "\n",
    "    def fit_model(self, data: pd.DataFrame, keyword: str, band_width:float = 0.0035) -> dict:\n",
    "        # keyword: 'driver' or 'rider'\n",
    "        model_set = {}\n",
    "\n",
    "        if keyword == 'driver':\n",
    "            index_key = 'end_location'\n",
    "        else:\n",
    "            index_key = 'start_location'\n",
    "\n",
    "        for time in range(1,25):\n",
    "            data_hr = data[data['time_step_index']==time]\n",
    "            xy_train  = np.vstack([data_hr[f'{index_key}_lat'], data_hr[f'{index_key}_long']]).T\n",
    "            kde_skl = KernelDensity(kernel='gaussian', bandwidth=band_width)\n",
    "            model_set[f'{time}'] = kde_skl.fit(xy_train)\n",
    "\n",
    "        return model_set\n",
    "    \n",
    "    def get_model(self):\n",
    "        rider_model = self.fit_model(self.rider_dataset_hr, keyword='rider')\n",
    "        driver_model = self.fit_model(self.driver_dataset_hr, keyword='driver')\n",
    "        \n",
    "        return rider_model, driver_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Build_Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1, model_2 = model.get_model()\n",
    "sample = model.sample_from_model(model_1['1'], 10)\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
