{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import gym\n",
    "import random\n",
    "import copy \n",
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "\n",
    "from drawnow import drawnow\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "#from ride_hailing_env import RideHailingENV\n",
    "\n",
    "import folium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Developing Notes:\n",
    "\n",
    "1) the obsevration dimension should be set as fixed, it can be the number of drivers/riders in each cell,\n",
    "    this will result in a observation space of 48*2 dimension.\n",
    "\n",
    "2) Dimension number  is important, converange is good when cell number is 4, not good when cell number is 30+, try to reduce cell number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Norm and Standardarize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下一步代码， 一个critic多个actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Ride_hailing env\n",
    "This is the file for defining the simulator for the ride-hailing environment.\n",
    "Functions defined in this file can be used for reinforcement learning.\n",
    "This is part of the master thesis project:\n",
    "Optimising matching radius for a ride-hailing system.\n",
    "\n",
    "# Use this .py script:\n",
    "env = RideHailingENV(grid_div=2)\n",
    "ob_rider, ob_driver, done = env.reset()\n",
    "ob_rider, ob_driver, reward = env.step(action, time_step, rend_step=False)\n",
    "\n",
    "# Test this environment for one step:\n",
    "env = RideHailingENV(grid_div=2)\n",
    "ob_rider, ob_driver, done = env.reset()\n",
    "action = np.full(4, 800)\n",
    "ob_rider, ob_driver, reward, done = env.step(action, hr_time=1, rend_step=True)\n",
    "print(reward, done)\n",
    "\n",
    "# Test this environment for one episode (5 hours):\n",
    "env = RideHailingENV(grid_div=2)\n",
    "ob_rider, ob_driver, done = env.reset()\n",
    "time_step, ep_reward, step_count = 1, 0, 0\n",
    "action = np.full(4, 800)\n",
    "while not done:\n",
    "    ob_rider, ob_driver, reward, done = env.step(action, time_step, rend_step=False)\n",
    "    ep_reward += reward\n",
    "    step_count += 1\n",
    "print(f'{ep_reward} | {step_count}')\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import gym\n",
    "import folium\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from h3 import h3\n",
    "from gym import spaces\n",
    "from folium.features import DivIcon\n",
    "from IPython.display import display\n",
    "from ride_hailing_match import Match\n",
    "from ride_hailing_location_model import Build_Model\n",
    "from pyproj import Transformer\n",
    "\n",
    "\n",
    "def wgs84_to_xy(x_arr: np.ndarray, y_arr: np.ndarray):\n",
    "    transformer = Transformer.from_crs('EPSG:4326', 'EPSG:32614')\n",
    "    x0 = 604082.94\n",
    "    y0 = 3328141.76\n",
    "    x_arr_new, y_arr_new = transformer.transform(x_arr, y_arr)\n",
    "    x_arr_new -= x0\n",
    "    y_arr_new -= y0\n",
    "    return x_arr_new.tolist(), y_arr_new.tolist()\n",
    "\n",
    "def xy_to_wgs84(xy_list):\n",
    "    transformer = Transformer.from_crs('EPSG:32614', 'EPSG:4326')\n",
    "    x_new = np.array(xy_list[0]) + 604082.94\n",
    "    y_new = np.array(xy_list[1]) + 3328141.76\n",
    "    lat_lon = transformer.transform(x_new, y_new)\n",
    "    return lat_lon\n",
    "\n",
    "def xy_to_wgs84_list(xy_list):\n",
    "    transformer = Transformer.from_crs('EPSG:32614', 'EPSG:4326')\n",
    "    x_arr = np.array(xy_list[0]) + 604082.94\n",
    "    y_arr = np.array(xy_list[1]) + 3328141.76\n",
    "    lat_list, lon_list = transformer.transform(x_arr, y_arr)\n",
    "    return lat_list.tolist(), lon_list.tolist()\n",
    "\n",
    "\n",
    "class Cell:\n",
    "    \"\"\"Gennerate cells\n",
    "    \"\"\"\n",
    "    def __init__(self, num_divisions) -> None:\n",
    "        self.lat_range = np.array([30.18, 30.32]) # Austin latitude range\n",
    "        self.lon_range = np.array([-97.81, -97.65]) # Austin longitude range\n",
    "        self.x_range, self.y_range = wgs84_to_xy(self.lat_range, self.lon_range)\n",
    "        self.num_divisions = num_divisions # how many part lat and lon are divided\n",
    "        pass\n",
    "   \n",
    "    def pass_info(self):\n",
    "        return self.lat_range, self.lon_range, self.x_range, self.y_range, self.num_divisions\n",
    "    \n",
    "    def get_cells(self, display_map: bool = False) -> list:\n",
    "        number =  self.num_divisions ** 2\n",
    "        cells = np.arange(number)\n",
    "\n",
    "        if display_map == False:\n",
    "            return cells\n",
    "        \n",
    "        else:\n",
    "            self.draw_cell()\n",
    "            return cells\n",
    "        \n",
    "    def draw_cell(self, state: np.array = None, radius_set: np.array = None):\n",
    "        # generate step data\n",
    "        lat_step = (self.lat_range[1] - self.lat_range[0]) / self.num_divisions\n",
    "        lon_step = (self.lon_range[1] - self.lon_range[0]) / self.num_divisions\n",
    "        m = folium.Map(location=[(self.lat_range[0] + self.lat_range[1]) / 2, (self.lon_range[0] + self.lon_range[1]) / 2], zoom_start=13)\n",
    "\n",
    "        for i in range(self.num_divisions):\n",
    "            for j in range(self.num_divisions):\n",
    "                lat_start = self.lat_range[0] + i * lat_step\n",
    "                lat_end = lat_start + lat_step\n",
    "                lon_start = self.lon_range[0] + j * lon_step\n",
    "                lon_end = lon_start + lon_step\n",
    "                grid_number = i * self.num_divisions + j\n",
    "\n",
    "                # Draw the grid\n",
    "                folium.Rectangle(\n",
    "                    bounds=[[lat_start, lon_start], [lat_end, lon_end]],\n",
    "                    color='blue',\n",
    "                    fill=True,\n",
    "                    fill_opacity=0.1\n",
    "                ).add_to(m)\n",
    "\n",
    "                # Add grid label\n",
    "                if state is None:\n",
    "                    folium.Marker(\n",
    "                        location=[lat_end-0.001, lon_start+0.002],\n",
    "                        popup=folium.Popup('<i>The center of map</i>'),\n",
    "                        tooltip='Center',\n",
    "                        icon=folium.DivIcon(html=f\"\"\"<b>Cell ID: {grid_number}</b>\"\"\",\n",
    "                                    class_name=\"mapText\"),\n",
    "                        ).add_to(m)\n",
    "                else:\n",
    "                    rider_count = int(state[grid_number * 2] * 50)\n",
    "                    driver_count = int(state[grid_number * 2 + 1] * 50)\n",
    "                    folium.Marker(\n",
    "                        location=[lat_end-0.001, lon_start+0.002],\n",
    "                        popup=folium.Popup('<i>The center of map</i>'),\n",
    "                        tooltip='Center',\n",
    "                        icon=folium.DivIcon(html=f'<b>Cell ID: {grid_number}<br>Rider Number: {rider_count}<br>Driver Number: {driver_count}</b>',\n",
    "                                    class_name=\"mapText\"),\n",
    "                        ).add_to(m)\n",
    "                \n",
    "                m.get_root().html.add_child(folium.Element(\"\"\"<style>.mapText {\n",
    "                        white-space: nowrap;\n",
    "                        color:Green;\n",
    "                        font-size:large\n",
    "                    }</style>\"\"\"))\n",
    "\n",
    "                # Draw radius if radius_set is provided\n",
    "                if radius_set is not None and grid_number < len(radius_set):\n",
    "                    radius = radius_set[grid_number]\n",
    "                    folium.Circle(\n",
    "                        location=[(lat_start + lat_end) / 2, (lon_start + lon_end) / 2],\n",
    "                        radius=radius,\n",
    "                        color='red',\n",
    "                        fill=True,\n",
    "                        fill_opacity=0.3\n",
    "                    ).add_to(m)\n",
    "\n",
    "        display(m)\n",
    "\n",
    "    def get_cell_id_wgs84(self, lat, lon):\n",
    "        if not (self.lat_range[0] <= lat <= self.lat_range[1]) or not (self.lon_range[0] <= lon <= self.lon_range[1]): # check if in the range\n",
    "            return None\n",
    "        lat_step = (self.lat_range[1] - self.lat_range[0]) / self.num_divisions\n",
    "        lon_step = (self.lon_range[1] - self.lon_range[0]) / self.num_divisions\n",
    "        lat_index = min(int((lat - self.lat_range[0]) / lat_step), self.num_divisions - 1)\n",
    "        lon_index = min(int((lon - self.lon_range[0]) / lon_step), self.num_divisions - 1)\n",
    "        grid_number = lat_index * self.num_divisions + lon_index\n",
    "        return grid_number\n",
    "    \n",
    "    def get_cell_id_xy(self, x_list, y_list):\n",
    "        cell_ids = []\n",
    "        x_step = (self.x_range[1] - self.x_range[0]) / self.num_divisions\n",
    "        y_step = (self.y_range[1] - self.y_range[0]) / self.num_divisions\n",
    "\n",
    "        for x, y in zip(x_list, y_list):\n",
    "            x_index = min(int((x - self.x_range[0]) / x_step), self.num_divisions - 1)\n",
    "            y_index = min(int((y - self.y_range[0]) / y_step), self.num_divisions - 1)\n",
    "            grid_number = x_index + y_index * self.num_divisions\n",
    "            cell_ids.append(grid_number)\n",
    "        \n",
    "        return cell_ids\n",
    "        \n",
    "\n",
    "class Gen_Model:\n",
    "    \"\"\"Sample locations from fitted model for riders and drivers in the map\n",
    "\n",
    "    This class is to generate locations for riders and drivers based on the given\n",
    "    distribution of their locations. This default model is estimated with Kernel \n",
    "    Density Estimation (KDE). The generated location is given in the format of \n",
    "    a pandas DataFrame, each row represents a unique rider/driver. Information\n",
    "    given in a row includes rider/driver's ID, H3 code, longitude and latitude.\n",
    "\n",
    "    Attributes:\n",
    "        model: an instance of Build_Model class containing models for riders and drivers\n",
    "        rider_model: a dictionary for 24 KDE distributions, describing the locational and timely distribution of riders\n",
    "        driver_model: a dictionary for 24 KDE distributions, describing the locational and timely distribution of drivers\n",
    "    \"\"\"\n",
    "    def __init__(self, num_div) -> None:\n",
    "        self.cell = Cell(num_div)\n",
    "        self.cell_ids = self.cell.get_cells(False)\n",
    "        self.model = Build_Model()\n",
    "        self.rider_model, self.driver_model = self.model.get_model()\n",
    "\n",
    "    def gen_drivers(self, number_of_drivers: int, hr_time: int, seed: int = None):\n",
    "        \"\"\"Sample locations for drivers\n",
    "        \n",
    "        Sample multiple locations for drivers based on the given locational distribution \n",
    "        of drivers. The default distribution model is KDE.\n",
    "\n",
    "        Parameters:\n",
    "            number_of_drivers: an int, indicating how many drivers are generated.\n",
    "            hr_time: an int, the value is the hour of the day, indicating which distribution model will be used.\n",
    "            resolution: an int, determines the number of cells in the map.\n",
    "\n",
    "        Returns:\n",
    "            driver_df: a pandas DataFrame, including information of generated drivers. \n",
    "        \"\"\"\n",
    "        if seed != None:\n",
    "            driver_locations = self.model.sample_from_model(self.driver_model[f'{hr_time}'], number_of_drivers, seed) # dtype = numpy ndarray\n",
    "        else:\n",
    "            driver_locations = self.model.sample_from_model(self.driver_model[f'{hr_time}'], number_of_drivers) # dtype = numpy ndarray\n",
    "        driver_ids = []\n",
    "        cell_ids = []\n",
    "\n",
    "        for driver_id, geo_info in enumerate(driver_locations):\n",
    "            cell_id = self.cell.get_cell_id_wgs84(geo_info[0], geo_info[1])\n",
    "            while cell_id is None:\n",
    "                geo_info = self.model.sample_from_model(self.rider_model[f'{hr_time}'], 1)[0] # dtype = numpy ndarray\n",
    "                cell_id = self.cell.get_cell_id_wgs84(geo_info[0], geo_info[1])\n",
    "                driver_locations[driver_id] = geo_info\n",
    "                #print('Re-sampled a driver!')\n",
    "            cell_ids.append(cell_id)\n",
    "            driver_ids.append(driver_id)\n",
    "\n",
    "        x_list, y_list = wgs84_to_xy(driver_locations.T[0], driver_locations.T[1])\n",
    "\n",
    "        driver_df = pd.DataFrame({'driver_id':driver_ids, 'cell_id':cell_ids, 'x':x_list, 'y':y_list, 'statue': 1, 'idle_time': 0})\n",
    "        # driver is avliable: 'statue' = 1, unavliable: 'statue' = 0\n",
    "        # driver_df[['driver_id', 'cell_id']] = driver_df[['driver_id', 'cell_id']].astype(int) # set data type to int\n",
    "\n",
    "        return driver_df\n",
    "\n",
    "    def gen_riders(self, number_of_riders: int, hr_time: int, seed: int = None):\n",
    "        \"\"\"Sample locations for riders\n",
    "        \n",
    "        Sample multiple locations for riders based on the given locational distribution \n",
    "        of riders. The default distribution model is KDE.\n",
    "\n",
    "        Parameters:\n",
    "            number_of_riders: an int, indicating how many riders are generated.\n",
    "            hr_time: an int, the value is the hour of the day, indicating which distribution model will be used.\n",
    "            resolution: an int, determines the number of cells in the map.\n",
    "\n",
    "        Returns:\n",
    "            rider_df: a pandas DataFrame, including information of generated riders. \n",
    "        \"\"\"\n",
    "        if seed != None:\n",
    "            rider_locations = self.model.sample_from_model(self.rider_model[f'{hr_time}'], number_of_riders, seed) # dtype = numpy ndarray\n",
    "        else:\n",
    "            rider_locations = self.model.sample_from_model(self.rider_model[f'{hr_time}'], number_of_riders) # dtype = numpy ndarray\n",
    "        rider_ids = []\n",
    "        cell_ids = []\n",
    "        \n",
    "        for rider_id, geo_info in enumerate(rider_locations):\n",
    "            cell_id = self.cell.get_cell_id_wgs84(geo_info[0], geo_info[1])\n",
    "            while cell_id is None:\n",
    "                geo_info = self.model.sample_from_model(self.rider_model[f'{hr_time}'], 1)[0] # dtype = numpy ndarray\n",
    "                cell_id = self.cell.get_cell_id_wgs84(geo_info[0], geo_info[1])\n",
    "                rider_locations[rider_id] = geo_info\n",
    "                #print('Re-sampled a rider!')\n",
    "            cell_ids.append(cell_id)\n",
    "            rider_ids.append(rider_id)\n",
    "\n",
    "        x_list, y_list = wgs84_to_xy(rider_locations.T[0], rider_locations.T[1])\n",
    "\n",
    "        rider_df = pd.DataFrame({'rider_id':rider_ids, 'cell_id':cell_ids, 'x':x_list, 'y':y_list, 'time_step_in_pool': 1})\n",
    "        # rider_df[['rider_id', 'cell_id', 'time_step_in_pool']] = rider_df[['rider_id', 'cell_id', 'time_step_in_pool']].astype(int) # set data type to int\n",
    "\n",
    "        return rider_df\n",
    "\n",
    "\n",
    "class RideHailingENV(gym.Env):\n",
    "    \"\"\"Simulation environment for project optimising matching radius for ride-hailing system\n",
    "\n",
    "    This class is the main simulator for the master thesis project optimising matching radius \n",
    "    for a ride-hailing system with reinforcement learning. The project is carried out in TU Delft. \n",
    "    This simulator is built base on the geographical information of Austin, Texas, USA. It intake\n",
    "    continous matching radius as the action, and the reward is the total net profit made by the \n",
    "    system within a day.\n",
    "\n",
    "    GOOD action for example:\n",
    "    action = np.ones(36)*800\n",
    "    action[[5, 13, 14, 15, 19, 20, 21, 26, 27]] = 400\n",
    "\n",
    "    Attributes:\n",
    "     lower_bound - lower bound of action space, minimum matching radius, unit is meters.\n",
    "     upper_bound - upper bound of action space, maximum matching radius, unit is meters.\n",
    "     model - make an instance of Gen_Model class, to generate riders and drivers for the simulator.\n",
    "     match - make an instance of Match class, to run the matching algorithm.\n",
    "     radius_initial - initial matching radius when reset the environment, unit is meters.\n",
    "     driver_num_ini - initial number of drivers, can be changed if set dynamic.\n",
    "     rider_num_ini - initial number of riders, rider number is changing among different steps.\n",
    "     fuel_unit_price - average travelling fuel cost per vehicle per kilometer in the US, the unit is US dollars.\n",
    "     time_window - time interval between every two matching process (Uber Batched matching), fixed among all steps, unit is minutes.\n",
    "     total_reward - total reward for the intake action.\n",
    "     gen_rate_rider - overall generating rate of riders, number of riders per time-window.\n",
    "     gen_rate_driver - active if vehicle number are set dynamic, number of new drivers per time-window.\n",
    "     ride_price - average ride price in Austin urban area, the value is estimated from Uber ride data in 2022.\n",
    "     rider_patience - the maximum number of steps a rider can stay in the matching pool.\n",
    "     p_unmatch_rider - penalty per unmatched rider, the value is cauculated base on the probability of losing a potential ride.\n",
    "     action_space - defines the numerical range of intake actions.\n",
    "     observation_space - defines the numerical range of overall observations.\n",
    "     sub_observation_space - defines the numerical range of observations within a cell.\n",
    "\n",
    "    Distance cost explain:\n",
    "     distance cost = car-buying cost + car repair and maintanance cost + fuel cost\n",
    "     car repair and maintanance cost = change tire per 200000km &1000 + change motor oil per 200000km $1200\n",
    "     car-buying cost: average car price in the us is $22000\n",
    "     fuel cost: averge fuel cost $1.3/L * averge fuel comsuption 9.3L/100km = $12.1/100km = $0.12/km\n",
    "     total = $11.65/km\n",
    "    \"\"\"\n",
    "    def __init__(self, grid_div, time_window: int = 0.25) -> None:\n",
    "\n",
    "        self.min_action = 50\n",
    "        self.max_action = 3000\n",
    "        self.num_divi = grid_div\n",
    "        self.cell = Cell(self.num_divi)\n",
    "        self.lat_range, self.lon_range, self.x_range, self.y_range, self.num_divisions = self.cell.pass_info()\n",
    "        self.model = Gen_Model(self.num_divi)\n",
    "        self.match = Match()\n",
    "        self.seed_ini = None\n",
    "\n",
    "        self.cell_ids = self.cell.get_cells(False)\n",
    "        self.cell_num = np.size(self.cell_ids)\n",
    "        self.radius_initial = 500\n",
    "        self.driver_num_ini = 50\n",
    "        self.rider_num_ini = 30\n",
    "        self.time_window = time_window\n",
    "        self.total_reward = 0\n",
    "        self.gen_rate_rider = 20\n",
    "        self.gen_rate_driver = 10\n",
    "        self.rider_patience = 0.75 # minutes\n",
    "        self.p_rider_left = 0.1 # punishment\n",
    "        self.p_unmatch_rider = 5\n",
    "        self.simulation_time = 60\n",
    "\n",
    "        self.drivers = None\n",
    "        self.riders = None\n",
    "        self.drivers_tmp = None\n",
    "        self.riders_tmp = None\n",
    "\n",
    "        self.rider_patience_step = self.rider_patience / self.time_window\n",
    "\n",
    "        self.action_dim = self.cell_num\n",
    "        self.state_dim = self.cell_num*2\n",
    "\n",
    "        self.max_step = self.simulation_time / self.time_window\n",
    "        self.axis = (self.min_action + self.max_action) / 2\n",
    "        self.scale = (self.max_action - self.min_action) / 2\n",
    "        self.multi_task_weight_factor = [0.4, 0.4, 0.2]\n",
    "        self.score_distance = lambda distance, max_distance=2000: max(0, min(1, distance / max_distance))\n",
    "        self.score_radius = lambda distance, max_distance=2500: max(0, min(1, 1- distance / max_distance))\n",
    "\n",
    "    def reset(self, time_ini: int = 1) -> np.array:\n",
    "        self.random_seed = self.seed_ini\n",
    "        self.drivers = self.model.gen_drivers(self.driver_num_ini, time_ini, self.random_seed)\n",
    "        self.drivers_in_service = np.zeros(self.driver_num_ini, dtype=np.int32)\n",
    "        self.drivers['driver_id'] = np.arange(self.drivers.shape[0])\n",
    "        self.riders = self.model.gen_riders(self.rider_num_ini, time_ini, self.random_seed)\n",
    "        self.riders['rider_id'] = np.arange(self.riders.shape[0])\n",
    "        self.rider_0, self.driver_0 = self.get_observe()\n",
    "        rider, driver = self.rider_0/self.driver_num_ini, self.driver_0/self.driver_num_ini # normalize\n",
    "        state_0 = np.empty(rider.size + driver.size, dtype=rider.dtype)\n",
    "        state_0[0::2] = rider\n",
    "        state_0[1::2] = driver\n",
    "        self.on_goal = 0\n",
    "        self.reward_ini(self.rider_0, self.driver_0)\n",
    "        state = state_0\n",
    "        self.step_count = 0\n",
    "        return state\n",
    "    \n",
    "    def min_max(self, action):\n",
    "        radius = action * self.scale + self.axis\n",
    "        return radius\n",
    "        \n",
    "    def step(self, action: np.array, hr_time: int, rend_step: bool = False, min_max: bool = True) -> tuple[float, dict, list]:\n",
    "        if min_max == True:\n",
    "            radius = self.min_max(action)\n",
    "        else:\n",
    "            radius = action\n",
    "        self.riders_tmp = self.riders.copy()\n",
    "        self.drivers_tmp = self.drivers.copy()\n",
    "\n",
    "        cell_ids = self.riders['cell_id']\n",
    "        r_radius = radius[cell_ids]\n",
    "\n",
    "        # get the matching pool\n",
    "        pool = self.__get_pool(self.dis_matrix, r_radius)\n",
    "\n",
    "        # matching process\n",
    "        match_statue = self.__match(pool)\n",
    "        _ = self.__execute_match(match_statue, pool, radius)\n",
    "\n",
    "        if match_statue:\n",
    "            aver_distance = sum(distance for _, _, distance in match_statue) / len(match_statue)\n",
    "            reward_match_rate = len(match_statue) / len(self.rider_0)\n",
    "            reward_driver_ult = len(match_statue) / len(self.driver_0)\n",
    "        else:\n",
    "            aver_distance = 0 \n",
    "            reward_match_rate = 0\n",
    "            reward_driver_ult = 0\n",
    "        reward = (reward_match_rate * self.multi_task_weight_factor[0] + \n",
    "                  self.score_distance(aver_distance) * self.multi_task_weight_factor[1] + \n",
    "                  reward_driver_ult * self.multi_task_weight_factor[2])\n",
    "        reward, done = self.train_radius_reward(radius)\n",
    "        \n",
    "        if rend_step:\n",
    "            state = [self.riders_tmp, self.drivers_tmp]\n",
    "            self.render(state, radius, match_statue)\n",
    "\n",
    "        self.riders, self.drivers = self.__state_transit(hr_time, match_statue)\n",
    "        rider, driver = self.get_observe()\n",
    "        self.rider_0, self.driver_0 = rider, driver\n",
    "        self.reward_ini(self.rider_0, self.driver_0)\n",
    "        rider, driver = rider/self.driver_num_ini, driver/self.driver_num_ini # normalize\n",
    "        state_0 = np.empty(rider.size + driver.size, dtype=rider.dtype)\n",
    "        state_0[0::2] = rider\n",
    "        state_0[1::2] = driver\n",
    "        state = state_0\n",
    "\n",
    "        return state, reward, done\n",
    "    \n",
    "    def reward_ini(self, riders, drivers):\n",
    "        total = riders + drivers\n",
    "        rider_ratio = riders / (total + 1e-6)\n",
    "        driver_ratio = drivers / (total + 1e-6)\n",
    "        sigmoid_rider_ratio = 1 / (1 + np.exp(-10 * (rider_ratio - 1.75*self.multi_task_weight_factor[0]))) \n",
    "        sigmoid_driver_ratio = 1 / (1 + np.exp(-10 * (driver_ratio - 1.75*self.multi_task_weight_factor[1])))\n",
    "        self.reward = self.min_action + (self.max_action - self.min_action) * (1 + sigmoid_rider_ratio - sigmoid_driver_ratio) / 2\n",
    "        pass\n",
    "\n",
    "    def train_radius_reward(self, action):\n",
    "        done = False\n",
    "        normalized_reward = (action - self.reward) / self.scale\n",
    "        score = 1 - np.abs(normalized_reward)\n",
    "        score = np.clip(score, -1, 1)\n",
    "        reward = score - 1\n",
    "        reward[score >= 0.95] += 1\n",
    "        return reward, done\n",
    "    \n",
    "    def test_step(self, action: np.array, hr_time: int, rend_step: bool = False, min_max: bool = True) -> tuple[float, dict, list]:\n",
    "        if min_max == True:\n",
    "            radius = self.min_max(action)\n",
    "        else:\n",
    "            radius = action\n",
    "        self.riders_tmp = self.riders.copy()\n",
    "        self.drivers_tmp = self.drivers.copy()\n",
    "        rider_0, driver_0 = self.get_observe()\n",
    "        cell_ids = self.riders['cell_id']\n",
    "        r_radius = radius[cell_ids]\n",
    "        # get the matching pool\n",
    "        pool = self.__get_pool(self.dis_matrix, r_radius)\n",
    "        # matching process\n",
    "        match_statue = self.__match(pool)\n",
    "        self.__execute_match(match_statue, pool, radius)\n",
    "        if match_statue:\n",
    "            aver_distance = sum(distance for _, _, distance in match_statue) / len(match_statue)\n",
    "            reward_match_rate = len(match_statue) / len(rider_0)\n",
    "            reward_driver_ult = len(match_statue) / len(driver_0)\n",
    "        else:\n",
    "            aver_distance = 0 # in case for tricky policies\n",
    "            reward_match_rate = 0\n",
    "            reward_driver_ult = 0\n",
    "        self.riders, self.drivers = self.__state_transit(hr_time, match_statue)\n",
    "        #reward_distance = aver_distance / self.max_action\n",
    "        reward_distance = self.score_distance(aver_distance)\n",
    "        #radius_avg = sum(radius)/self.cell_num\n",
    "        performance = reward_match_rate * self.multi_task_weight_factor[0] + self.score_radius(sum(radius)/self.cell_num) * self.multi_task_weight_factor[1] # + reward_driver_ult * self.multi_task_weight_factor[2]\n",
    "        #performance -= (1 + np.exp(-0.04 * (radius - self.min_action))) * (1 + np.exp(0.005 * (radius - self.max_action))) - 1\n",
    "        rider, driver = self.get_observe()\n",
    "        self.rider_0, self.driver_0 = rider, driver\n",
    "        rider, driver = rider/self.driver_num_ini, driver/self.driver_num_ini # normalize\n",
    "        state_0 = np.empty(rider.size + driver.size, dtype=rider.dtype)\n",
    "        state_0[0::2] = rider\n",
    "        state_0[1::2] = driver\n",
    "        state = state_0\n",
    "        return state, performance, False\n",
    "    \n",
    "    def get_observe(self): # observation is number of riders/drivers in each cell\n",
    "        rider_counts = self.riders['cell_id'].value_counts().sort_index().reindex(range(self.cell_num), fill_value=0).to_numpy()\n",
    "        supply_driver = self.drivers[self.drivers['statue']==1]\n",
    "        supply_driver = self.drivers\n",
    "        driver_counts = supply_driver['cell_id'].value_counts().sort_index().reindex(range(self.cell_num), fill_value=0).to_numpy()\n",
    "\n",
    "        #avg_distance = np.full(self.cell_num, 3000)  # Initialize with 6000 for cells with no riders\n",
    "        rider_vec = self.riders[['x', 'y']].values\n",
    "        driver_vec = self.drivers[['x', 'y']].values\n",
    "        self.dis_matrix = self.__vector_dis(rider_vec, driver_vec)\n",
    "        \"\"\"\n",
    "        for cell_id in range(self.cell_num):\n",
    "            riders_in_cell = self.riders[self.riders['cell_id'] == cell_id].index\n",
    "            if len(riders_in_cell) > 0:\n",
    "                distances = self.dis_matrix[riders_in_cell].min(axis=1)\n",
    "                distance = distances.mean()\n",
    "                avg_distance[cell_id] = distance\n",
    "        avg_distance = np.clip(avg_distance, 0, 3000)\"\"\"\n",
    "        return rider_counts, driver_counts#, avg_distance\n",
    "    \n",
    "    def check_done(self):\n",
    "        if self.step_count >= self.max_step -1: #or self.riders.shape[0] == 0:\n",
    "            done = True\n",
    "        else:\n",
    "            done = False\n",
    "        return done\n",
    "\n",
    "    def __get_pool(self, dis_matrix: list, radius_set: int) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        form a matching pool for all the riders and available drivers whithin the matching radius.\n",
    "\n",
    "        Parameters:\n",
    "            riders - locations, numbers of all the riders.\n",
    "            drivers - locations, numbers of all the drivers.\n",
    "            radius - matching radius for each cell, riders in the same cell have the same matching radius.\n",
    "\n",
    "        Returns:\n",
    "            returns a list consist all the possible matches and the distance between them.\n",
    "        \"\"\"\n",
    "        match_pool = []\n",
    "        for i in range(dis_matrix.shape[0]):\n",
    "            sub_pool = []\n",
    "            radius_rider = radius_set[i]\n",
    "            driver_1 = np.where(dis_matrix[i] <= radius_rider)[1]\n",
    "            driver_2 = self.drivers.index[self.drivers['statue'] == 1]\n",
    "            driver = list(np.intersect1d(driver_1, driver_2))\n",
    "            rider = list(np.ones(np.size(driver), dtype=int)*i)\n",
    "            dis = dis_matrix[i, driver].tolist()[0]\n",
    "            sub_pool.extend([rider])\n",
    "            sub_pool.extend([driver])\n",
    "            sub_pool.extend([dis])\n",
    "            sub_pool = list(map(list, zip(*sub_pool)))\n",
    "            match_pool.extend(sub_pool)\n",
    "        return match_pool\n",
    "            \n",
    "    def __match(self, pool: list): # MM: Maximum Matching, OM: Optimised Matching\n",
    "        \"\"\"\n",
    "        excute matching algorithm to find the optimal match for the given matching pool.\n",
    "\n",
    "        Parameters:\n",
    "         pool - matching pool with distance. \n",
    "\n",
    "        Returns:\n",
    "         match statue with matched pairs and their distance. \n",
    "        \"\"\"\n",
    "        matched_pairs = self.match.match(pool, method='Munkres')\n",
    "        return matched_pairs\n",
    "    \n",
    "    def __execute_match(self, match_statue:list, match_pool: list, radius: np.array) -> tuple[float, tuple]:\n",
    "        \"\"\"\n",
    "        apply the matched pairs to the map, update riders and drivers, observe reward and penalty.\n",
    "\n",
    "        Parameters:\n",
    "        riders - locations, numbers of all the riders.\n",
    "        drivers - locations, numbers of all the drivers.\n",
    "        match_statue - matched pair of riders and drivers with the distance between them.\n",
    "\n",
    "        Returns:\n",
    "        reward - the net monetary profit made from the ride-hailing system within a step.\n",
    "        pool_next - next state of the environment after taking the action.\n",
    "        \"\"\"\n",
    "        # calculate total distance and rewards\n",
    "        reward = 0 #- 200 * self.distance_cost\n",
    "\n",
    "        if match_statue:\n",
    "            #aver_distance = sum(distance for _, _, distance in match_statue) / len(match_statue)\n",
    "            riders_to_drop, drivers_to_drop = zip(*[(rider, driver) for rider, driver, _ in match_statue])\n",
    "            riders_to_drop, drivers_to_drop = list(riders_to_drop), list(drivers_to_drop)\n",
    "        else:\n",
    "            #aver_distance = 0 # in case for tricky policies\n",
    "            riders_to_drop, drivers_to_drop = [], []\n",
    "                 \n",
    "        #reward_distance = self.score_distance(aver_distance)\n",
    "\n",
    "        #print(complete_rate, reward_distance, reward_driver_ult)\n",
    "\n",
    "        #reward = complete_rate * self.multi_task_weight_factor[0] + reward_distance * self.multi_task_weight_factor[1] + reward_driver_ult * self.multi_task_weight_factor[2]\n",
    "        #reward = complete_rate * self.multi_task_weight_factor[0] - self.score_radius(sum(radius) / self.cell_num) * self.multi_task_weight_factor[1]\n",
    "\n",
    "        self.riders = self.riders.drop(riders_to_drop)\n",
    "        self.drivers_in_service[drivers_to_drop] += 2\n",
    "        self.drivers.loc[drivers_to_drop, 'statue'] = 0\n",
    "        self.drivers.loc[drivers_to_drop, 'idle_time'] = 0\n",
    "\n",
    "        self.riders['time_step_in_pool'] += 1\n",
    "        #reward -= self.p_rider_left * self.riders[self.riders['time_step_in_pool']>self.rider_patience].shape[0]\n",
    "\n",
    "        return 0\n",
    "    \n",
    "    def __vector_dis(self, rider_vec, driver_vec):\n",
    "        m = np.shape(rider_vec)[0]\n",
    "        n = np.shape(driver_vec)[0]\n",
    "        M = np.dot(rider_vec, driver_vec.T)\n",
    "        H = np.tile(np.matrix(np.square(rider_vec).sum(axis=1)).T,(1,n))\n",
    "        K = np.tile(np.matrix(np.square(driver_vec).sum(axis=1)),(m,1))\n",
    "        return np.sqrt(-2 * M + H + K)\n",
    "    \n",
    "    def __state_transit(self, hr_time: int, match_statue: list) -> dict: \n",
    "        \"\"\"\n",
    "        update the current state and give the state of the next step.\n",
    "        v1_update: do not gennerate new riders, terminal is all the riders are matched or left\n",
    "\n",
    "        Parameters:\n",
    "         state - the current state, locations of riders and drivers.\n",
    "         hr_time - hourly time of a day, this is used to generate new riders and drivers.\n",
    "\n",
    "        Returns:\n",
    "         returns the locations of riders and drivers for the next step.\n",
    "        \"\"\"\n",
    "        ride_num = np.size(match_statue)\n",
    "\n",
    "        # update riders\n",
    "        \n",
    "        self.riders = self.riders.drop(self.riders[self.riders['time_step_in_pool']>self.rider_patience_step].index) # inpatient riders quit the matching pool\n",
    "        rider_size = self.gen_rate_rider\n",
    "        new_riders = self.model.gen_riders(rider_size, hr_time, self.random_seed)\n",
    "        rider_next = pd.concat((self.riders, new_riders), axis=0)\n",
    "\n",
    "        self.drivers.loc[self.drivers_in_service == 0, 'statue'] = 1 # drivers finished ride\n",
    "\n",
    "        # update drivers - driver reposition\n",
    "        self.drivers.loc[self.drivers['statue'] == 1, 'idle_time'] += 1 # update idle time\n",
    "        condition = (self.drivers['idle_time'] == 20) & (self.drivers['statue'] == 1)\n",
    "        self.drivers.loc[condition, 'x'] += np.random.choice([-800, 800], size=condition.sum())\n",
    "        self.drivers.loc[condition, 'y'] += np.random.choice([-800, 800], size=condition.sum())\n",
    "        self.drivers.loc[condition, 'idle_time'] = 0 # reset idle time\n",
    "\n",
    "        # update drivers - driver idling\n",
    "        self.drivers_in_service[self.drivers_in_service != 0] -= 1\n",
    "        self.drivers['x'] += np.random.uniform(-400, 400, size=self.drivers.shape[0])\n",
    "        self.drivers['y'] += np.random.uniform(-400, 400, size=self.drivers.shape[0])\n",
    "\n",
    "        # check latitude and longitude border\n",
    "        self.drivers['x'] = np.clip(self.drivers['x'], self.x_range[0], self.x_range[1]) # check latitude range\n",
    "        self.drivers['y'] = np.clip(self.drivers['y'], self.y_range[0], self.y_range[1]) # check longitude range\n",
    "\n",
    "        # update cell ids for drivers\n",
    "        self.drivers['cell_id'] = self.cell.get_cell_id_xy(self.drivers['x'], self.drivers['y']) \n",
    "\n",
    "        #rider_next = rider_next.reset_index(drop=True)\n",
    "        self.riders = rider_next.reset_index(drop=True)\n",
    "        self.drivers = self.drivers.reset_index(drop=True)\n",
    "\n",
    "        # re-index drivers and riders\n",
    "        driver_index = self.drivers.shape[0]\n",
    "        self.drivers['driver_id'] = np.arange(driver_index)\n",
    "        rider_index = self.riders.shape[0]\n",
    "        self.riders['rider_id'] = np.arange(rider_index)\n",
    "\n",
    "        return self.riders, self.drivers\n",
    "\n",
    "    def render(self, state: tuple, radius_set: dict, match_statue: list, color_set: tuple = ['red', 'blue'], folium_map=None) -> None:\n",
    "        \"\"\"\n",
    "        visualise the state and action for one step, red circle is matching range (within matching radius),\n",
    "        green lines are the links for matched pairs.\n",
    "\n",
    "        Parameters:\n",
    "         state - the current state, locations of riders and drivers.\n",
    "         radius_set - matching radius for each cell.\n",
    "         match_statue - matched pair of riders and drivers with the distance between them.\n",
    "         folium_map - map object.\n",
    "        \"\"\"\n",
    "\n",
    "        riders = state[0]\n",
    "        drivers = state[1]\n",
    "        drivers = drivers[drivers['statue'] == 1]\n",
    "        drivers.reset_index(drop=True, inplace=True)\n",
    "        matched_riders = []\n",
    "        matched_drivers = []\n",
    "        if match_statue != []:\n",
    "            matched_riders = pd.DataFrame(match_statue)[0].to_list()\n",
    "            matched_drivers = pd.DataFrame(match_statue)[1].to_list()\n",
    "\n",
    "        matched_rider_location = {}\n",
    "        matched_driver_location = {}\n",
    "\n",
    "        lat_step = (self.lat_range[1] - self.lat_range[0]) / self.num_divisions\n",
    "        lon_step = (self.lon_range[1] - self.lon_range[0]) / self.num_divisions\n",
    "        m = folium.Map(location=[(self.lat_range[0] + self.lat_range[1]) / 2, (self.lon_range[0] + self.lon_range[1]) / 2], zoom_start=13)\n",
    "        for i in range(self.num_divisions):\n",
    "            for j in range(self.num_divisions):\n",
    "                lat_start = self.lat_range[0] + i * lat_step\n",
    "                lat_end = lat_start + lat_step\n",
    "                lon_start = self.lon_range[0] + j * lon_step\n",
    "                lon_end = lon_start + lon_step\n",
    "                grid_number = i * self.num_divisions + j\n",
    "                # Draw the grid\n",
    "                folium.Rectangle(\n",
    "                    bounds=[[lat_start, lon_start], [lat_end, lon_end]],\n",
    "                    color='blue',\n",
    "                    fill=True,\n",
    "                    fill_opacity=0.1\n",
    "                ).add_to(m)\n",
    "                # Add grid number\n",
    "                folium.Marker(\n",
    "                    location=[(lat_start + lat_end) / 2, (lon_start + lon_end) / 2],\n",
    "                    icon=folium.DivIcon(html=f'<div style=\"font-size: 18pt\">{grid_number}</div>')\n",
    "                ).add_to(m)\n",
    "       \n",
    "        # add driver markers\n",
    "        for i in range(drivers.shape[0]):\n",
    "            driver_wgs = xy_to_wgs84([drivers.loc[i]['x'], drivers.loc[i]['y']])\n",
    "            folium.Marker(\n",
    "                location=driver_wgs,\n",
    "                icon=folium.Icon(\n",
    "                    color=color_set[0],\n",
    "                    prefix='fa',\n",
    "                    icon='car'\n",
    "                    )\n",
    "                ).add_to(m)\n",
    "            if drivers.loc[i]['driver_id'] in matched_drivers:\n",
    "                matched_driver_location[f'{int(drivers.loc[i][\"driver_id\"])}'] = driver_wgs\n",
    "          \n",
    "        # add rider markers and matching radius\n",
    "        for j in range(riders.shape[0]):\n",
    "            rider_wgs = xy_to_wgs84([riders.loc[j]['x'], riders.loc[j]['y']])\n",
    "            folium.Marker(\n",
    "                location=rider_wgs,\n",
    "                icon=folium.Icon(\n",
    "                    color=color_set[1],\n",
    "                    prefix='fa',\n",
    "                    icon='male'\n",
    "                    )\n",
    "                ).add_to(m)\n",
    "            \n",
    "            folium.Circle(\n",
    "                    radius=float(radius_set[int(riders.loc[j]['cell_id'])]),\n",
    "                    location=rider_wgs,\n",
    "                    color=\"red\",\n",
    "                    weight=1,\n",
    "                    fill=True,\n",
    "                    fill_opacity=0.1\n",
    "                ).add_to(m)\n",
    "            if riders.loc[j]['rider_id'] in matched_riders:\n",
    "                matched_rider_location[f'{int(riders.loc[j][\"rider_id\"])}'] = rider_wgs\n",
    "       \n",
    "        for rider, driver, dis in match_statue:\n",
    "            folium.PolyLine(\n",
    "                locations=[matched_rider_location[f'{int(rider)}'], matched_driver_location[f'{int(driver)}']],\n",
    "                color='green', \n",
    "                weight=5,\n",
    "                tooltip='matched_links'\n",
    "                ).add_to(m)\n",
    "    \n",
    "        display(m)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory(object):\n",
    "  def __init__(self, memory_size=30000):\n",
    "    self.memory = deque(maxlen=memory_size)\n",
    "    self.memory_size = memory_size\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.memory)\n",
    "\n",
    "  def append(self, item):\n",
    "    self.memory.append(item)\n",
    "\n",
    "  def sample_batch(self, batch_size):\n",
    "    idx = np.random.permutation(len(self.memory))[:batch_size]\n",
    "    return [self.memory[i] for i in idx]\n",
    "  \n",
    "  def get_memory(self):\n",
    "    return self.memory\n",
    "\n",
    "# Simple Ornstein-Uhlenbeck Noise generator\n",
    "class OUNoise(object):\n",
    "  \"\"\" Ornstein-Uhlenbeck process noise \"\"\"\n",
    "  def __init__(self, size, mu=0.0, theta=0.15, sigma=0.3):\n",
    "        \"\"\" Initialize parameters and noise process \"\"\"\n",
    "        self.mu = mu * np.ones(size)\n",
    "        self.theta = theta \n",
    "        self.sigma = sigma\n",
    "        self.size = size\n",
    "        self.reset()\n",
    "\n",
    "  def reset(self):\n",
    "        \"\"\" Reset the interal state (= noise) to mean (mu). \"\"\"\n",
    "        self.state = copy.copy(self.mu)\n",
    "\n",
    "  def sample(self):\n",
    "        \"\"\" Update internal state and return it as a noise sample \"\"\"\n",
    "        self.state += self.theta * (self.mu - self.state) + self.sigma * np.random.standard_normal(self.size)\n",
    "        return self.state\n",
    "  \n",
    "\n",
    "class Actor(nn.Module):\n",
    "  def __init__(self, state_dim, action_dim):\n",
    "    super(Actor, self).__init__()\n",
    "    self.fc_state = nn.Linear(state_dim, 128)\n",
    "    self.fc_1 = nn.Linear(128, 256)\n",
    "    self.fc_2 = nn.Linear(256, 128)\n",
    "    self.fc_out = nn.Linear(128, action_dim, bias=True) # was False\n",
    "\n",
    "    init.xavier_normal_(self.fc_state.weight)\n",
    "    init.xavier_normal_(self.fc_1.weight)\n",
    "    init.xavier_normal_(self.fc_2.weight)\n",
    "    init.xavier_normal_(self.fc_out.weight)\n",
    "\n",
    "  def forward(self, state):\n",
    "    out = F.elu(self.fc_state(state))\n",
    "    out = F.elu(self.fc_1(out))\n",
    "    out = F.elu(self.fc_2(out))\n",
    "    out = F.tanh(self.fc_out(out))\n",
    "    return out\n",
    "\n",
    "\n",
    "class Critic(nn.Module):\n",
    "  def __init__(self, state_dim, action_dim):\n",
    "    super(Critic, self).__init__()\n",
    "    self.fc_state = nn.Linear(state_dim, 128)\n",
    "    self.fc_action = nn.Linear(action_dim, 128)\n",
    "    self.fc_1 = nn.Linear(256, 256)\n",
    "    self.fc_2 = nn.Linear(256, 128)\n",
    "    self.fc_value = nn.Linear(128, 1, bias=True) # was False\n",
    "\n",
    "    init.xavier_normal_(self.fc_state.weight)\n",
    "    init.xavier_normal_(self.fc_action.weight)\n",
    "    init.xavier_normal_(self.fc_1.weight)\n",
    "    init.xavier_normal_(self.fc_2.weight)\n",
    "    init.xavier_normal_(self.fc_value.weight)\n",
    "\n",
    "  def forward(self, state, action):\n",
    "    out_s = F.elu(self.fc_state(state))\n",
    "    out_a = F.elu(self.fc_action(action))\n",
    "    out = torch.cat([out_s, out_a], dim=1)\n",
    "    out = F.elu(self.fc_1(out))\n",
    "    out = F.elu(self.fc_2(out))\n",
    "    out = self.fc_value(out)\n",
    "    return out\n",
    "\n",
    "\n",
    "class DDPG:\n",
    "  \"\"\"\n",
    "  Norm params\n",
    "    iter 1: rider:  mean = 0.30813, std = 0.99681 | driver:  mean = 2.49566, std = 3.66580\n",
    "    iter 2: rider:  mean = 0.90319, std = 2.39189 | driver:  mean = 2.53821, std = 3.70436\n",
    "    iter 3: rider:  mean = 22.1580, std = 19.3104 | driver:  mean = 19.4841, std = 12.1474\n",
    "    iter 4: rider:  mean = 15.4974, std = 16.4297 | driver:  mean = 10.3216, std = 10.2087\n",
    "\n",
    "    for i in range(self.args.num_divi**2):\n",
    "      self.actor, self.actor_target = [], []\n",
    "      self.actor.append(Actor(self.state_dim, self.action_dim))\n",
    "      self.actor_target.append(Actor(self.state_dim, self.action_dim))\n",
    "      self.actor_targets[i].load_state_dict(self.actors[i].state_dict()) # initial target net weights from policy net\n",
    "\n",
    "  \"\"\"\n",
    "  def __init__(self, args) -> None:\n",
    "    self.args = args\n",
    "    self.env = RideHailingENV(grid_div=self.args.num_divi)\n",
    "    self.get_neighbors()\n",
    "    self.action_dim = 1\n",
    "    self.state_dim = 2\n",
    "    self.actor = [Actor(self.state_dim, self.action_dim) for _ in range(self.args.num_divi**2)]\n",
    "    self.actor_target = [Actor(self.state_dim, self.action_dim) for _ in range(self.args.num_divi**2)]\n",
    "    self.critic = Critic(self.state_dim, self.action_dim)\n",
    "    self.critic_target = Critic(self.state_dim, self.action_dim)\n",
    "    [actor_target.load_state_dict(actor.state_dict()) for actor_target, actor in zip(self.actor_target, self.actor)] # initial target net weights from policy net\n",
    "    self.critic_target.load_state_dict(self.critic.state_dict()) # initial target net weights from value net\n",
    "    self.actor_optimizer = [optim.Adam(actor.parameters(), lr=self.args.lr_actor) for actor in self.actor]\n",
    "    self.critic_optimizer = optim.Adam(self.critic.parameters(), lr=self.args.lr_critic)\n",
    "    self.max_action = self.env.max_action\n",
    "    self.min_action = self.env.min_action\n",
    "    self.axis = (self.min_action + self.max_action) / 2\n",
    "    self.scale = (self.max_action - self.min_action) / 2\n",
    "    self.noise = OUNoise(self.action_dim, theta=0.3, sigma=0.6) # import noise # smaller noise\n",
    "    self.last_score_plot = []\n",
    "    self.avg_score_plot = [0]\n",
    "    self.memory_main = Memory(memory_size=20000)\n",
    "    self.memory_good_act = Memory(memory_size=10000)\n",
    "    self.loss_check = []\n",
    "    self.rider_num = []\n",
    "    self.max_score = 0\n",
    "    pass\n",
    "\n",
    "  def get_action(self, actor_net, state):\n",
    "    if not isinstance(state, torch.Tensor):\n",
    "      state = torch.from_numpy(state.reshape(1, -1)).float()\n",
    "    action = actor_net(state)[0]\n",
    "    return action\n",
    "  \n",
    "  def get_action_batch(self, actor_net, state_batch):\n",
    "    if not isinstance(state_batch, torch.Tensor):\n",
    "      state_batch = torch.from_numpy(state_batch).float()\n",
    "    action = actor_net(state_batch)\n",
    "    return action             \n",
    "  \n",
    "  def get_radius(self, action): # ues this function only if env only intake exact radius\n",
    "    radius = action * self.scale + self.axis\n",
    "    return radius\n",
    "\n",
    "  def get_q_value(self, critic_net, state_batch, action):\n",
    "    if not isinstance(state_batch, torch.Tensor):\n",
    "      state_batch = torch.from_numpy(state_batch).float()\n",
    "    if not isinstance(action, torch.Tensor):\n",
    "      action = torch.from_numpy(action).float()\n",
    "    q_value = critic_net(state_batch, action)\n",
    "    return q_value\n",
    "\n",
    "  def update_actor(self, state_batch, i):\n",
    "    action = self.actor[i](state_batch)\n",
    "    q_value = -torch.mean(self.critic(state_batch, action)) \n",
    "    self.actor_optimizer[i].zero_grad() # calculate the gradient to update actor\n",
    "    q_value.backward()\n",
    "    self.actor_optimizer[i].step()\n",
    "    pass\n",
    "\n",
    "  def update_critic(self, state_batch, action, target):\n",
    "    q_value = self.critic(state_batch, action)\n",
    "    loss = F.mse_loss(q_value, target) # minimize loss to update critic\n",
    "    self.critic_optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    self.critic_optimizer.step()\n",
    "    check = loss.detach().numpy()\n",
    "    self.loss_check.append(check)\n",
    "    pass\n",
    "\n",
    "  def soft_update(self, target, source, tau):\n",
    "    for target_param, param in zip(target.parameters(), source.parameters()):\n",
    "      target_param.data.copy_(target_param.data * (1.0 - tau) + param.data * tau) # weights target and source\n",
    "\n",
    "  def draw_fig(self):\n",
    "    plt.plot(self.last_score_plot, '-')\n",
    "    #plt.plot(self.avg_score_plot, 'r-')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Reward')\n",
    "    plt.title('Reinforcement Learning Process')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "  def get_neighbors(self):\n",
    "    self.neighbors = {\n",
    "      0: np.array([0, -1, -1, -1, -1, 1, -1, 4, 5]),\n",
    "      1: np.array([1, -1, -1, -1, 0, 2, 4, 5, 6]),\n",
    "      2: np.array([2, -1, -1, -1, 1, 3, 5, 6, 7]),\n",
    "      3: np.array([3, -1, -1, -1, 2, -1, 6, 7, -1]),\n",
    "      4: np.array([4, -1, 0, 1, -1, 5, -1, 8, 9]),\n",
    "      5: np.array([5, 0, 1, 2, 4, 6, 8, 9, 10]),\n",
    "      6: np.array([6, 1, 2, 3, 5, 7, 9, 10, 11]),\n",
    "      7: np.array([7, 2, 3, -1, 6, -1, 10, 11, -1]),\n",
    "      8: np.array([8, -1, 4, 5, -1, 9, -1, 12, 13]),\n",
    "      9: np.array([9, 4, 5, 6, 8, 10, 12, 13, 14]),\n",
    "      10: np.array([10, 5, 6, 7, 9, 11, 13, 14, 15]),\n",
    "      11: np.array([11, 6, 7, -1, 10, -1, 14, 15, -1]),\n",
    "      12: np.array([12, -1, 8, 9, -1, 13, -1, -1, -1]),\n",
    "      13: np.array([13, 8, 9, 10, 12, 14, -1, -1, -1]),\n",
    "      14: np.array([14, 9, 10, 11, 13, 15, -1, -1, -1]),\n",
    "      15: np.array([15, 10, 11, -1, 14, -1, -1, -1, -1])\n",
    "    }\n",
    "\n",
    "  def run_ddpg(self):\n",
    "    state = self.env.reset()\n",
    "    done = False\n",
    "    iteration_now = 0\n",
    "    iteration = 0\n",
    "    episode = 0\n",
    "    episode_score = 0\n",
    "    episode_steps = 0\n",
    "    memory_warmup = self.args.batch_size * 3\n",
    "    self.noise.reset()\n",
    "\n",
    "    while episode < self.args.max_episode:\n",
    "      #print('\\rIteration {} | Episode {} | Result -> '.format(iteration_now, episode), end='')\n",
    "      action = np.zeros(self.env.cell_num)\n",
    "      state_i_set = np.empty((0, 2), dtype=float)\n",
    "      # Iterate over each cell index\n",
    "      for i in range(self.env.cell_num):  # Since there are 16 cells\n",
    "        # Check if there are neighbors defined for cell i in neighbors\n",
    "        neighbors_i = self.neighbors[i]\n",
    "        state_i = state[i*2:(i+1)*2]\n",
    "        # Fill rider and driver counts for neighboring cells in state_i\n",
    "        for j in range(1, len(neighbors_i)):  # Start from index 1 to skip the current cell itself\n",
    "            neighbor = neighbors_i[j]\n",
    "            if neighbor != -1:  # If neighbor is not False (i.e., it's a valid index)\n",
    "                neighbor_index = int(neighbor)\n",
    "                state_i[0] += 0.0125 * state[neighbor_index*2]\n",
    "                state_i[1] += 0.0125 * state[(neighbor_index)*2+1]\n",
    "        action[i] = self.get_action(self.actor[i], state_i).detach().numpy()[0]\n",
    "        state_i_set = np.append(state_i_set, [state_i], axis=0)\n",
    "\n",
    "      # blend determinstic action with random action during exploration, noise will become samller during the process\n",
    "      if episode < self.args.max_explore_eps:\n",
    "        p = episode / self.args.max_explore_eps\n",
    "        action = action * p + (1 - p) * self.noise.sample()\n",
    "      action = np.clip(action, -1, 1) # select valid action range\n",
    "      state_next, reward, done = self.env.step(action, self.args.hr_time)\n",
    "        \n",
    "      # Assuming self.env.cell_num is defined somewhere\n",
    "      indices_of_interest = [5, 6, 9, 10]\n",
    "\n",
    "      # Iterate over each cell index\n",
    "      for i in indices_of_interest:\n",
    "        state_i_next = state_next[i*2:(i+1)*2]\n",
    "        neighbors_i = self.neighbors[i]\n",
    "        for j in range(1, len(neighbors_i)):\n",
    "          neighbor = neighbors_i[j]\n",
    "          if neighbor != -1:\n",
    "            neighbor_index = int(neighbor)\n",
    "            state_i_next[0] += 0.0125 * state_next[neighbor_index*2]\n",
    "            state_i_next[1] += 0.0125 * state_next[(neighbor_index)*2+1]\n",
    "\n",
    "          action_i = action[i]\n",
    "          # Store transitions in self.memory_main and self.memory_good_act\n",
    "          transition = [state_i_set[i], action_i, reward[i], state_i_next, done]\n",
    "          self.memory_main.append(transition)\n",
    "          if reward[i] >= 0.98:\n",
    "              self.memory_good_act.append(transition)\n",
    "\n",
    "      if iteration >= memory_warmup:\n",
    "        memory_batch_0 = self.memory_main.sample_batch(int(self.args.batch_size * 0.5))\n",
    "        memory_batch_1 = self.memory_good_act.sample_batch(int(self.args.batch_size * 0.6))\n",
    "        memory_batch = memory_batch_0 + memory_batch_1\n",
    "        state_batch, action_batch, reward_batch, next_state_batch, done_batch = map(lambda x: torch.tensor(x).float(), zip(*memory_batch))\n",
    "        action_batch = action_batch.unsqueeze(1)\n",
    "\n",
    "        action_next = self.get_action_batch(self.actor_target[9], next_state_batch)\n",
    "        Q_next = self.get_q_value(self.critic_target, next_state_batch, action_next).detach()\n",
    "        Q_target_batch = reward_batch[:, None] + self.args.gamma * (1 - done_batch[:, None]) * Q_next\n",
    "        self.update_critic(state_batch, action_batch, Q_target_batch)\n",
    "        for i in range(self.env.cell_num):\n",
    "          self.update_actor(state_batch, i) \n",
    "\n",
    "        self.soft_update(self.actor_target[9], self.actor[9], self.args.tau_act)\n",
    "        self.soft_update(self.critic_target, self.critic, self.args.tau_cri)\n",
    "\n",
    "      episode_score += sum(reward)/self.env.cell_num\n",
    "      episode_steps += 1\n",
    "      iteration_now += 1\n",
    "      iteration += 1\n",
    "\n",
    "      if done or episode_steps == 200:\n",
    "        print('Episode {:03d} | Episode Score:{:.03f}'.format(episode, episode_score))\n",
    "        #print(f'Policy now: {radius}')\n",
    "        self.avg_score_plot.append(self.avg_score_plot[-1] * 0.99 + episode_score * 0.01)\n",
    "        self.last_score_plot.append(episode_score)\n",
    "\n",
    "        episode += 1\n",
    "        episode_score = 0\n",
    "        episode_steps = 0\n",
    "        iteration_now = 0\n",
    "\n",
    "        state = self.env.reset()\n",
    "        self.noise.reset()\n",
    "\n",
    "        #plt.plot(self.rider_num, '-')\n",
    "        #plt.show()\n",
    "        #self.rider_num=[]\n",
    "      else:\n",
    "        state = state_next # state tranist\n",
    "\n",
    "    #drawnow(self.draw_fig) # drawnow function is for dynamic update\n",
    "    self.draw_fig()\n",
    "    return state, self.actor, self.memory_main, self.memory_good_act\n",
    "  \n",
    "  def debug_info(self):\n",
    "    return self.loss_check\n",
    "  \n",
    "  def get_optimal(self):\n",
    "    return self.actor_, self.critic_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='PyTorch DDPG solution of Ride_hailing Radius')\n",
    "parser.add_argument('--gamma', type=float, default=0.98)\n",
    "parser.add_argument('--lr_actor', type=float, default=0.0001) # default 0.0001\n",
    "parser.add_argument('--lr_critic', type=float, default=0.0008) # default 0.001\n",
    "parser.add_argument('--tau_act', type=float, default=0.0005) # critic output weights between critic and target networks, default 0.001\n",
    "parser.add_argument('--tau_cri', type=float, default=0.001) \n",
    "parser.add_argument('--batch_size', type=int, default=250)\n",
    "parser.add_argument('--max_episode', type=int, default=1000)\n",
    "parser.add_argument('--max_explore_eps', type=int, default=500)\n",
    "parser.add_argument('--hr_time', type=int, default=18)\n",
    "parser.add_argument('--num_divi', type=int, default=4)\n",
    "args = parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 000 | Episode Score:-136.907\n",
      "Episode 001 | Episode Score:-125.300\n",
      "Episode 002 | Episode Score:-151.563\n",
      "Episode 003 | Episode Score:-130.942\n",
      "Episode 004 | Episode Score:-135.205\n",
      "Episode 005 | Episode Score:-142.774\n",
      "Episode 006 | Episode Score:-140.801\n",
      "Episode 007 | Episode Score:-139.462\n",
      "Episode 008 | Episode Score:-140.737\n",
      "Episode 009 | Episode Score:-148.021\n",
      "Episode 010 | Episode Score:-154.910\n",
      "Episode 011 | Episode Score:-148.021\n",
      "Episode 012 | Episode Score:-135.778\n",
      "Episode 013 | Episode Score:-152.014\n",
      "Episode 014 | Episode Score:-128.619\n",
      "Episode 015 | Episode Score:-152.533\n",
      "Episode 016 | Episode Score:-140.846\n",
      "Episode 017 | Episode Score:-143.400\n",
      "Episode 018 | Episode Score:-141.517\n",
      "Episode 019 | Episode Score:-130.451\n",
      "Episode 020 | Episode Score:-135.482\n",
      "Episode 021 | Episode Score:-139.218\n",
      "Episode 022 | Episode Score:-138.591\n",
      "Episode 023 | Episode Score:-131.468\n",
      "Episode 024 | Episode Score:-140.868\n",
      "Episode 025 | Episode Score:-142.989\n",
      "Episode 026 | Episode Score:-138.906\n",
      "Episode 027 | Episode Score:-139.943\n",
      "Episode 028 | Episode Score:-136.384\n",
      "Episode 029 | Episode Score:-147.358\n",
      "Episode 030 | Episode Score:-141.364\n",
      "Episode 031 | Episode Score:-132.103\n",
      "Episode 032 | Episode Score:-136.547\n",
      "Episode 033 | Episode Score:-145.623\n",
      "Episode 034 | Episode Score:-125.064\n",
      "Episode 035 | Episode Score:-137.582\n",
      "Episode 036 | Episode Score:-130.602\n",
      "Episode 037 | Episode Score:-121.203\n",
      "Episode 038 | Episode Score:-130.949\n",
      "Episode 039 | Episode Score:-117.259\n",
      "Episode 040 | Episode Score:-154.953\n",
      "Episode 041 | Episode Score:-125.540\n",
      "Episode 042 | Episode Score:-133.929\n",
      "Episode 043 | Episode Score:-135.108\n",
      "Episode 044 | Episode Score:-145.047\n",
      "Episode 045 | Episode Score:-142.242\n",
      "Episode 046 | Episode Score:-130.215\n",
      "Episode 047 | Episode Score:-120.483\n",
      "Episode 048 | Episode Score:-129.989\n",
      "Episode 049 | Episode Score:-126.793\n",
      "Episode 050 | Episode Score:-130.625\n",
      "Episode 051 | Episode Score:-145.053\n",
      "Episode 052 | Episode Score:-127.150\n",
      "Episode 053 | Episode Score:-122.367\n",
      "Episode 054 | Episode Score:-129.053\n",
      "Episode 055 | Episode Score:-110.387\n",
      "Episode 056 | Episode Score:-131.194\n",
      "Episode 057 | Episode Score:-133.302\n",
      "Episode 058 | Episode Score:-122.676\n",
      "Episode 059 | Episode Score:-132.079\n",
      "Episode 060 | Episode Score:-132.590\n",
      "Episode 061 | Episode Score:-127.156\n",
      "Episode 062 | Episode Score:-122.303\n",
      "Episode 063 | Episode Score:-117.847\n",
      "Episode 064 | Episode Score:-130.573\n",
      "Episode 065 | Episode Score:-127.332\n",
      "Episode 066 | Episode Score:-138.217\n",
      "Episode 067 | Episode Score:-123.343\n",
      "Episode 068 | Episode Score:-145.187\n",
      "Episode 069 | Episode Score:-132.799\n",
      "Episode 070 | Episode Score:-119.559\n",
      "Episode 071 | Episode Score:-143.044\n",
      "Episode 072 | Episode Score:-127.310\n",
      "Episode 073 | Episode Score:-124.341\n",
      "Episode 074 | Episode Score:-132.493\n",
      "Episode 075 | Episode Score:-119.619\n",
      "Episode 076 | Episode Score:-134.366\n",
      "Episode 077 | Episode Score:-124.711\n",
      "Episode 078 | Episode Score:-113.671\n",
      "Episode 079 | Episode Score:-134.658\n",
      "Episode 080 | Episode Score:-116.871\n",
      "Episode 081 | Episode Score:-126.597\n",
      "Episode 082 | Episode Score:-128.171\n",
      "Episode 083 | Episode Score:-127.122\n",
      "Episode 084 | Episode Score:-117.447\n",
      "Episode 085 | Episode Score:-123.676\n",
      "Episode 086 | Episode Score:-121.697\n",
      "Episode 087 | Episode Score:-114.358\n",
      "Episode 088 | Episode Score:-126.816\n",
      "Episode 089 | Episode Score:-112.752\n",
      "Episode 090 | Episode Score:-124.168\n",
      "Episode 091 | Episode Score:-125.169\n",
      "Episode 092 | Episode Score:-120.009\n",
      "Episode 093 | Episode Score:-120.360\n",
      "Episode 094 | Episode Score:-119.152\n",
      "Episode 095 | Episode Score:-122.554\n",
      "Episode 096 | Episode Score:-110.804\n",
      "Episode 097 | Episode Score:-113.757\n",
      "Episode 098 | Episode Score:-128.944\n",
      "Episode 099 | Episode Score:-116.576\n",
      "Episode 100 | Episode Score:-114.307\n",
      "Episode 101 | Episode Score:-117.209\n",
      "Episode 102 | Episode Score:-100.276\n",
      "Episode 103 | Episode Score:-111.668\n",
      "Episode 104 | Episode Score:-126.161\n",
      "Episode 105 | Episode Score:-123.874\n",
      "Episode 106 | Episode Score:-128.612\n",
      "Episode 107 | Episode Score:-112.733\n",
      "Episode 108 | Episode Score:-117.380\n",
      "Episode 109 | Episode Score:-119.945\n",
      "Episode 110 | Episode Score:-112.591\n",
      "Episode 111 | Episode Score:-119.226\n",
      "Episode 112 | Episode Score:-118.886\n",
      "Episode 113 | Episode Score:-111.876\n",
      "Episode 114 | Episode Score:-106.439\n",
      "Episode 115 | Episode Score:-116.153\n",
      "Episode 116 | Episode Score:-113.646\n",
      "Episode 117 | Episode Score:-111.185\n",
      "Episode 118 | Episode Score:-116.306\n",
      "Episode 119 | Episode Score:-124.293\n",
      "Episode 120 | Episode Score:-107.461\n",
      "Episode 121 | Episode Score:-114.493\n",
      "Episode 122 | Episode Score:-117.877\n",
      "Episode 123 | Episode Score:-106.292\n",
      "Episode 124 | Episode Score:-116.919\n",
      "Episode 125 | Episode Score:-93.354\n",
      "Episode 126 | Episode Score:-88.646\n",
      "Episode 127 | Episode Score:-109.666\n",
      "Episode 128 | Episode Score:-112.849\n",
      "Episode 129 | Episode Score:-126.006\n",
      "Episode 130 | Episode Score:-121.664\n",
      "Episode 131 | Episode Score:-100.528\n",
      "Episode 132 | Episode Score:-105.240\n",
      "Episode 133 | Episode Score:-112.537\n",
      "Episode 134 | Episode Score:-108.246\n",
      "Episode 135 | Episode Score:-110.542\n",
      "Episode 136 | Episode Score:-112.627\n",
      "Episode 137 | Episode Score:-112.546\n",
      "Episode 138 | Episode Score:-106.973\n",
      "Episode 139 | Episode Score:-112.955\n",
      "Episode 140 | Episode Score:-113.123\n",
      "Episode 141 | Episode Score:-105.957\n",
      "Episode 142 | Episode Score:-96.940\n",
      "Episode 143 | Episode Score:-121.432\n",
      "Episode 144 | Episode Score:-113.651\n",
      "Episode 145 | Episode Score:-118.639\n",
      "Episode 146 | Episode Score:-102.870\n",
      "Episode 147 | Episode Score:-97.246\n",
      "Episode 148 | Episode Score:-118.597\n",
      "Episode 149 | Episode Score:-107.145\n",
      "Episode 150 | Episode Score:-100.412\n",
      "Episode 151 | Episode Score:-106.629\n",
      "Episode 152 | Episode Score:-106.768\n",
      "Episode 153 | Episode Score:-96.501\n",
      "Episode 154 | Episode Score:-98.487\n",
      "Episode 155 | Episode Score:-101.787\n",
      "Episode 156 | Episode Score:-93.306\n",
      "Episode 157 | Episode Score:-90.234\n",
      "Episode 158 | Episode Score:-97.844\n",
      "Episode 159 | Episode Score:-94.936\n",
      "Episode 160 | Episode Score:-100.716\n",
      "Episode 161 | Episode Score:-102.431\n",
      "Episode 162 | Episode Score:-98.415\n",
      "Episode 163 | Episode Score:-90.413\n",
      "Episode 164 | Episode Score:-97.794\n",
      "Episode 165 | Episode Score:-86.476\n",
      "Episode 166 | Episode Score:-91.479\n",
      "Episode 167 | Episode Score:-98.724\n",
      "Episode 168 | Episode Score:-103.771\n",
      "Episode 169 | Episode Score:-96.946\n",
      "Episode 170 | Episode Score:-93.736\n",
      "Episode 171 | Episode Score:-103.224\n",
      "Episode 172 | Episode Score:-89.696\n",
      "Episode 173 | Episode Score:-106.080\n",
      "Episode 174 | Episode Score:-89.768\n",
      "Episode 175 | Episode Score:-87.949\n",
      "Episode 176 | Episode Score:-92.628\n",
      "Episode 177 | Episode Score:-91.980\n",
      "Episode 178 | Episode Score:-98.674\n",
      "Episode 179 | Episode Score:-85.004\n",
      "Episode 180 | Episode Score:-94.218\n",
      "Episode 181 | Episode Score:-90.928\n",
      "Episode 182 | Episode Score:-88.025\n",
      "Episode 183 | Episode Score:-95.538\n",
      "Episode 184 | Episode Score:-84.328\n",
      "Episode 185 | Episode Score:-92.966\n",
      "Episode 186 | Episode Score:-81.372\n",
      "Episode 187 | Episode Score:-94.592\n",
      "Episode 188 | Episode Score:-98.445\n",
      "Episode 189 | Episode Score:-91.671\n",
      "Episode 190 | Episode Score:-91.573\n",
      "Episode 191 | Episode Score:-82.811\n",
      "Episode 192 | Episode Score:-87.092\n",
      "Episode 193 | Episode Score:-93.608\n",
      "Episode 194 | Episode Score:-94.936\n",
      "Episode 195 | Episode Score:-93.303\n",
      "Episode 196 | Episode Score:-85.502\n",
      "Episode 197 | Episode Score:-89.870\n",
      "Episode 198 | Episode Score:-78.565\n",
      "Episode 199 | Episode Score:-76.737\n",
      "Episode 200 | Episode Score:-87.496\n",
      "Episode 201 | Episode Score:-83.292\n",
      "Episode 202 | Episode Score:-80.457\n",
      "Episode 203 | Episode Score:-76.542\n",
      "Episode 204 | Episode Score:-79.096\n",
      "Episode 205 | Episode Score:-78.435\n",
      "Episode 206 | Episode Score:-83.439\n",
      "Episode 207 | Episode Score:-85.980\n",
      "Episode 208 | Episode Score:-89.508\n",
      "Episode 209 | Episode Score:-78.953\n",
      "Episode 210 | Episode Score:-82.513\n",
      "Episode 211 | Episode Score:-76.183\n",
      "Episode 212 | Episode Score:-75.704\n",
      "Episode 213 | Episode Score:-74.779\n",
      "Episode 214 | Episode Score:-79.685\n",
      "Episode 215 | Episode Score:-73.576\n",
      "Episode 216 | Episode Score:-82.313\n",
      "Episode 217 | Episode Score:-73.645\n",
      "Episode 218 | Episode Score:-89.532\n",
      "Episode 219 | Episode Score:-77.694\n",
      "Episode 220 | Episode Score:-80.130\n",
      "Episode 221 | Episode Score:-83.332\n",
      "Episode 222 | Episode Score:-75.716\n",
      "Episode 223 | Episode Score:-70.416\n",
      "Episode 224 | Episode Score:-74.884\n",
      "Episode 225 | Episode Score:-68.664\n",
      "Episode 226 | Episode Score:-81.911\n",
      "Episode 227 | Episode Score:-70.914\n",
      "Episode 228 | Episode Score:-79.315\n",
      "Episode 229 | Episode Score:-77.646\n",
      "Episode 230 | Episode Score:-81.289\n",
      "Episode 231 | Episode Score:-70.117\n",
      "Episode 232 | Episode Score:-79.545\n",
      "Episode 233 | Episode Score:-81.779\n",
      "Episode 234 | Episode Score:-69.454\n",
      "Episode 235 | Episode Score:-74.343\n",
      "Episode 236 | Episode Score:-80.816\n",
      "Episode 237 | Episode Score:-81.090\n",
      "Episode 238 | Episode Score:-75.505\n",
      "Episode 239 | Episode Score:-68.185\n",
      "Episode 240 | Episode Score:-77.230\n",
      "Episode 241 | Episode Score:-64.311\n",
      "Episode 242 | Episode Score:-74.560\n",
      "Episode 243 | Episode Score:-79.800\n",
      "Episode 244 | Episode Score:-77.513\n",
      "Episode 245 | Episode Score:-71.124\n",
      "Episode 246 | Episode Score:-72.191\n",
      "Episode 247 | Episode Score:-76.328\n",
      "Episode 248 | Episode Score:-67.492\n",
      "Episode 249 | Episode Score:-70.050\n",
      "Episode 250 | Episode Score:-71.513\n",
      "Episode 251 | Episode Score:-71.448\n",
      "Episode 252 | Episode Score:-83.319\n",
      "Episode 253 | Episode Score:-68.989\n",
      "Episode 254 | Episode Score:-70.485\n",
      "Episode 255 | Episode Score:-64.767\n",
      "Episode 256 | Episode Score:-71.181\n",
      "Episode 257 | Episode Score:-68.387\n",
      "Episode 258 | Episode Score:-70.215\n",
      "Episode 259 | Episode Score:-75.698\n",
      "Episode 260 | Episode Score:-68.125\n",
      "Episode 261 | Episode Score:-67.652\n",
      "Episode 262 | Episode Score:-68.252\n",
      "Episode 263 | Episode Score:-62.624\n",
      "Episode 264 | Episode Score:-59.963\n",
      "Episode 265 | Episode Score:-55.808\n",
      "Episode 266 | Episode Score:-66.801\n",
      "Episode 267 | Episode Score:-61.378\n",
      "Episode 268 | Episode Score:-59.957\n",
      "Episode 269 | Episode Score:-57.161\n",
      "Episode 270 | Episode Score:-57.784\n",
      "Episode 271 | Episode Score:-59.454\n",
      "Episode 272 | Episode Score:-65.007\n",
      "Episode 273 | Episode Score:-72.777\n",
      "Episode 274 | Episode Score:-54.583\n",
      "Episode 275 | Episode Score:-59.003\n",
      "Episode 276 | Episode Score:-52.863\n",
      "Episode 277 | Episode Score:-62.181\n",
      "Episode 278 | Episode Score:-55.816\n",
      "Episode 279 | Episode Score:-57.004\n",
      "Episode 280 | Episode Score:-53.314\n",
      "Episode 281 | Episode Score:-62.360\n",
      "Episode 282 | Episode Score:-54.744\n",
      "Episode 283 | Episode Score:-60.467\n",
      "Episode 284 | Episode Score:-52.016\n",
      "Episode 285 | Episode Score:-52.522\n",
      "Episode 286 | Episode Score:-56.629\n",
      "Episode 287 | Episode Score:-51.943\n",
      "Episode 288 | Episode Score:-49.119\n",
      "Episode 289 | Episode Score:-66.372\n",
      "Episode 290 | Episode Score:-51.976\n",
      "Episode 291 | Episode Score:-59.511\n",
      "Episode 292 | Episode Score:-51.182\n",
      "Episode 293 | Episode Score:-49.200\n",
      "Episode 294 | Episode Score:-57.972\n",
      "Episode 295 | Episode Score:-59.082\n",
      "Episode 296 | Episode Score:-54.162\n",
      "Episode 297 | Episode Score:-42.861\n",
      "Episode 298 | Episode Score:-49.576\n",
      "Episode 299 | Episode Score:-53.167\n",
      "Episode 300 | Episode Score:-51.779\n",
      "Episode 301 | Episode Score:-46.786\n",
      "Episode 302 | Episode Score:-50.989\n",
      "Episode 303 | Episode Score:-45.045\n",
      "Episode 304 | Episode Score:-56.852\n",
      "Episode 305 | Episode Score:-54.994\n",
      "Episode 306 | Episode Score:-46.499\n",
      "Episode 307 | Episode Score:-45.666\n",
      "Episode 308 | Episode Score:-46.048\n",
      "Episode 309 | Episode Score:-58.683\n",
      "Episode 310 | Episode Score:-47.363\n",
      "Episode 311 | Episode Score:-48.518\n",
      "Episode 312 | Episode Score:-48.609\n",
      "Episode 313 | Episode Score:-42.458\n",
      "Episode 314 | Episode Score:-59.708\n",
      "Episode 315 | Episode Score:-51.475\n",
      "Episode 316 | Episode Score:-43.476\n",
      "Episode 317 | Episode Score:-36.548\n",
      "Episode 318 | Episode Score:-35.882\n",
      "Episode 319 | Episode Score:-51.492\n",
      "Episode 320 | Episode Score:-41.958\n",
      "Episode 321 | Episode Score:-46.951\n",
      "Episode 322 | Episode Score:-37.108\n",
      "Episode 323 | Episode Score:-39.636\n",
      "Episode 324 | Episode Score:-39.643\n",
      "Episode 325 | Episode Score:-44.566\n",
      "Episode 326 | Episode Score:-35.630\n",
      "Episode 327 | Episode Score:-44.988\n",
      "Episode 328 | Episode Score:-45.056\n",
      "Episode 329 | Episode Score:-40.948\n",
      "Episode 330 | Episode Score:-38.412\n",
      "Episode 331 | Episode Score:-29.380\n",
      "Episode 332 | Episode Score:-29.315\n",
      "Episode 333 | Episode Score:-33.735\n",
      "Episode 334 | Episode Score:-39.625\n",
      "Episode 335 | Episode Score:-35.605\n",
      "Episode 336 | Episode Score:-33.823\n",
      "Episode 337 | Episode Score:-30.049\n",
      "Episode 338 | Episode Score:-28.463\n",
      "Episode 339 | Episode Score:-28.847\n",
      "Episode 340 | Episode Score:-35.187\n",
      "Episode 341 | Episode Score:-32.482\n",
      "Episode 342 | Episode Score:-29.908\n",
      "Episode 343 | Episode Score:-35.944\n",
      "Episode 344 | Episode Score:-27.889\n",
      "Episode 345 | Episode Score:-25.450\n",
      "Episode 346 | Episode Score:-27.053\n",
      "Episode 347 | Episode Score:-32.315\n",
      "Episode 348 | Episode Score:-28.491\n",
      "Episode 349 | Episode Score:-25.354\n",
      "Episode 350 | Episode Score:-31.345\n",
      "Episode 351 | Episode Score:-33.418\n",
      "Episode 352 | Episode Score:-21.086\n",
      "Episode 353 | Episode Score:-30.198\n",
      "Episode 354 | Episode Score:-22.855\n",
      "Episode 355 | Episode Score:-23.205\n",
      "Episode 356 | Episode Score:-20.260\n",
      "Episode 357 | Episode Score:-32.603\n",
      "Episode 358 | Episode Score:-25.318\n",
      "Episode 359 | Episode Score:-27.029\n",
      "Episode 360 | Episode Score:-26.588\n",
      "Episode 361 | Episode Score:-20.668\n",
      "Episode 362 | Episode Score:-20.093\n",
      "Episode 363 | Episode Score:-5.751\n",
      "Episode 364 | Episode Score:-16.353\n",
      "Episode 365 | Episode Score:-22.301\n",
      "Episode 366 | Episode Score:-16.718\n",
      "Episode 367 | Episode Score:-19.147\n",
      "Episode 368 | Episode Score:-18.459\n",
      "Episode 369 | Episode Score:-20.859\n",
      "Episode 370 | Episode Score:-24.790\n",
      "Episode 371 | Episode Score:-15.409\n",
      "Episode 372 | Episode Score:-22.713\n",
      "Episode 373 | Episode Score:-19.416\n",
      "Episode 374 | Episode Score:-12.044\n",
      "Episode 375 | Episode Score:-19.265\n",
      "Episode 376 | Episode Score:-13.361\n",
      "Episode 377 | Episode Score:-21.867\n",
      "Episode 378 | Episode Score:-14.134\n",
      "Episode 379 | Episode Score:-16.049\n",
      "Episode 380 | Episode Score:-3.313\n",
      "Episode 381 | Episode Score:-3.379\n",
      "Episode 382 | Episode Score:-3.205\n",
      "Episode 383 | Episode Score:-5.142\n",
      "Episode 384 | Episode Score:-13.085\n",
      "Episode 385 | Episode Score:2.003\n",
      "Episode 386 | Episode Score:-2.044\n",
      "Episode 387 | Episode Score:-8.187\n",
      "Episode 388 | Episode Score:-5.168\n",
      "Episode 389 | Episode Score:-8.653\n",
      "Episode 390 | Episode Score:-0.662\n",
      "Episode 391 | Episode Score:2.625\n",
      "Episode 392 | Episode Score:0.822\n",
      "Episode 393 | Episode Score:-5.986\n",
      "Episode 394 | Episode Score:-12.073\n",
      "Episode 395 | Episode Score:-0.967\n",
      "Episode 396 | Episode Score:-6.333\n",
      "Episode 397 | Episode Score:-7.335\n",
      "Episode 398 | Episode Score:1.201\n",
      "Episode 399 | Episode Score:1.936\n",
      "Episode 400 | Episode Score:-0.652\n",
      "Episode 401 | Episode Score:-0.989\n",
      "Episode 402 | Episode Score:2.550\n",
      "Episode 403 | Episode Score:-2.895\n",
      "Episode 404 | Episode Score:-3.877\n",
      "Episode 405 | Episode Score:6.331\n",
      "Episode 406 | Episode Score:2.050\n",
      "Episode 407 | Episode Score:2.857\n",
      "Episode 408 | Episode Score:-4.695\n",
      "Episode 409 | Episode Score:-4.801\n",
      "Episode 410 | Episode Score:1.056\n",
      "Episode 411 | Episode Score:5.985\n",
      "Episode 412 | Episode Score:-7.120\n",
      "Episode 413 | Episode Score:-5.646\n",
      "Episode 414 | Episode Score:1.922\n",
      "Episode 415 | Episode Score:-0.919\n",
      "Episode 416 | Episode Score:2.448\n",
      "Episode 417 | Episode Score:2.504\n",
      "Episode 418 | Episode Score:0.890\n",
      "Episode 419 | Episode Score:13.063\n",
      "Episode 420 | Episode Score:1.467\n",
      "Episode 421 | Episode Score:8.828\n",
      "Episode 422 | Episode Score:18.860\n",
      "Episode 423 | Episode Score:14.152\n",
      "Episode 424 | Episode Score:9.567\n",
      "Episode 425 | Episode Score:9.866\n",
      "Episode 426 | Episode Score:13.753\n",
      "Episode 427 | Episode Score:15.030\n",
      "Episode 428 | Episode Score:14.425\n",
      "Episode 429 | Episode Score:8.011\n",
      "Episode 430 | Episode Score:17.356\n",
      "Episode 431 | Episode Score:19.127\n",
      "Episode 432 | Episode Score:23.478\n",
      "Episode 433 | Episode Score:6.033\n",
      "Episode 434 | Episode Score:18.258\n",
      "Episode 435 | Episode Score:18.643\n",
      "Episode 436 | Episode Score:18.559\n",
      "Episode 437 | Episode Score:18.905\n",
      "Episode 438 | Episode Score:18.339\n",
      "Episode 439 | Episode Score:5.030\n",
      "Episode 440 | Episode Score:6.883\n",
      "Episode 441 | Episode Score:10.186\n",
      "Episode 442 | Episode Score:17.509\n",
      "Episode 443 | Episode Score:23.333\n",
      "Episode 444 | Episode Score:27.377\n",
      "Episode 445 | Episode Score:18.362\n",
      "Episode 446 | Episode Score:21.148\n",
      "Episode 447 | Episode Score:34.518\n",
      "Episode 448 | Episode Score:32.747\n",
      "Episode 449 | Episode Score:34.957\n",
      "Episode 450 | Episode Score:28.457\n",
      "Episode 451 | Episode Score:32.653\n",
      "Episode 452 | Episode Score:32.147\n",
      "Episode 453 | Episode Score:32.087\n",
      "Episode 454 | Episode Score:33.868\n",
      "Episode 455 | Episode Score:39.579\n",
      "Episode 456 | Episode Score:37.381\n",
      "Episode 457 | Episode Score:38.491\n",
      "Episode 458 | Episode Score:32.477\n",
      "Episode 459 | Episode Score:45.659\n",
      "Episode 460 | Episode Score:27.572\n",
      "Episode 461 | Episode Score:27.095\n",
      "Episode 462 | Episode Score:48.740\n",
      "Episode 463 | Episode Score:43.618\n",
      "Episode 464 | Episode Score:40.302\n",
      "Episode 465 | Episode Score:43.172\n",
      "Episode 466 | Episode Score:47.621\n",
      "Episode 467 | Episode Score:65.773\n",
      "Episode 468 | Episode Score:43.602\n",
      "Episode 469 | Episode Score:62.994\n",
      "Episode 470 | Episode Score:54.537\n",
      "Episode 471 | Episode Score:61.564\n",
      "Episode 472 | Episode Score:60.266\n",
      "Episode 473 | Episode Score:70.400\n",
      "Episode 474 | Episode Score:77.760\n",
      "Episode 475 | Episode Score:55.152\n",
      "Episode 476 | Episode Score:75.727\n",
      "Episode 477 | Episode Score:75.422\n",
      "Episode 478 | Episode Score:74.585\n",
      "Episode 479 | Episode Score:75.168\n",
      "Episode 480 | Episode Score:59.747\n",
      "Episode 481 | Episode Score:87.069\n",
      "Episode 482 | Episode Score:101.460\n",
      "Episode 483 | Episode Score:89.432\n",
      "Episode 484 | Episode Score:98.801\n",
      "Episode 485 | Episode Score:87.249\n",
      "Episode 486 | Episode Score:97.754\n",
      "Episode 487 | Episode Score:96.008\n",
      "Episode 488 | Episode Score:101.987\n",
      "Episode 489 | Episode Score:97.590\n",
      "Episode 490 | Episode Score:90.659\n",
      "Episode 491 | Episode Score:87.878\n",
      "Episode 492 | Episode Score:109.439\n",
      "Episode 493 | Episode Score:72.755\n",
      "Episode 494 | Episode Score:97.372\n",
      "Episode 495 | Episode Score:71.147\n",
      "Episode 496 | Episode Score:68.502\n",
      "Episode 497 | Episode Score:66.960\n",
      "Episode 498 | Episode Score:90.800\n",
      "Episode 499 | Episode Score:99.085\n",
      "Episode 500 | Episode Score:82.480\n",
      "Episode 501 | Episode Score:83.524\n",
      "Episode 502 | Episode Score:86.088\n",
      "Episode 503 | Episode Score:86.187\n",
      "Episode 504 | Episode Score:99.128\n",
      "Episode 505 | Episode Score:101.650\n",
      "Episode 506 | Episode Score:106.511\n",
      "Episode 507 | Episode Score:98.409\n",
      "Episode 508 | Episode Score:84.894\n",
      "Episode 509 | Episode Score:81.030\n",
      "Episode 510 | Episode Score:99.935\n",
      "Episode 511 | Episode Score:84.598\n",
      "Episode 512 | Episode Score:102.180\n",
      "Episode 513 | Episode Score:80.105\n",
      "Episode 514 | Episode Score:96.459\n",
      "Episode 515 | Episode Score:90.547\n",
      "Episode 516 | Episode Score:94.156\n",
      "Episode 517 | Episode Score:93.496\n",
      "Episode 518 | Episode Score:111.173\n",
      "Episode 519 | Episode Score:112.020\n",
      "Episode 520 | Episode Score:97.468\n",
      "Episode 521 | Episode Score:97.592\n",
      "Episode 522 | Episode Score:97.131\n",
      "Episode 523 | Episode Score:100.914\n",
      "Episode 524 | Episode Score:103.068\n",
      "Episode 525 | Episode Score:106.783\n",
      "Episode 526 | Episode Score:120.253\n",
      "Episode 527 | Episode Score:100.922\n",
      "Episode 528 | Episode Score:90.314\n",
      "Episode 529 | Episode Score:91.285\n",
      "Episode 530 | Episode Score:88.813\n",
      "Episode 531 | Episode Score:84.932\n",
      "Episode 532 | Episode Score:71.424\n",
      "Episode 533 | Episode Score:64.422\n",
      "Episode 534 | Episode Score:88.979\n",
      "Episode 535 | Episode Score:86.342\n",
      "Episode 536 | Episode Score:98.431\n",
      "Episode 537 | Episode Score:94.104\n",
      "Episode 538 | Episode Score:101.212\n",
      "Episode 539 | Episode Score:94.622\n",
      "Episode 540 | Episode Score:70.317\n",
      "Episode 541 | Episode Score:82.259\n",
      "Episode 542 | Episode Score:77.559\n",
      "Episode 543 | Episode Score:101.158\n",
      "Episode 544 | Episode Score:95.626\n",
      "Episode 545 | Episode Score:95.935\n",
      "Episode 546 | Episode Score:96.737\n",
      "Episode 547 | Episode Score:97.277\n",
      "Episode 548 | Episode Score:83.692\n",
      "Episode 549 | Episode Score:92.133\n",
      "Episode 550 | Episode Score:74.226\n",
      "Episode 551 | Episode Score:76.637\n",
      "Episode 552 | Episode Score:82.934\n",
      "Episode 553 | Episode Score:96.141\n",
      "Episode 554 | Episode Score:93.550\n",
      "Episode 555 | Episode Score:113.854\n",
      "Episode 556 | Episode Score:116.143\n",
      "Episode 557 | Episode Score:108.344\n",
      "Episode 558 | Episode Score:113.087\n",
      "Episode 559 | Episode Score:103.585\n",
      "Episode 560 | Episode Score:103.962\n",
      "Episode 561 | Episode Score:102.404\n",
      "Episode 562 | Episode Score:96.032\n",
      "Episode 563 | Episode Score:94.582\n",
      "Episode 564 | Episode Score:110.203\n",
      "Episode 565 | Episode Score:105.016\n",
      "Episode 566 | Episode Score:100.456\n",
      "Episode 567 | Episode Score:109.077\n",
      "Episode 568 | Episode Score:106.074\n",
      "Episode 569 | Episode Score:92.330\n",
      "Episode 570 | Episode Score:99.593\n",
      "Episode 571 | Episode Score:74.317\n",
      "Episode 572 | Episode Score:89.501\n",
      "Episode 573 | Episode Score:108.897\n",
      "Episode 574 | Episode Score:103.915\n",
      "Episode 575 | Episode Score:75.491\n",
      "Episode 576 | Episode Score:77.221\n",
      "Episode 577 | Episode Score:80.486\n",
      "Episode 578 | Episode Score:96.949\n",
      "Episode 579 | Episode Score:85.583\n",
      "Episode 580 | Episode Score:87.833\n",
      "Episode 581 | Episode Score:85.789\n",
      "Episode 582 | Episode Score:80.181\n",
      "Episode 583 | Episode Score:75.008\n",
      "Episode 584 | Episode Score:75.382\n",
      "Episode 585 | Episode Score:84.074\n",
      "Episode 586 | Episode Score:37.552\n",
      "Episode 587 | Episode Score:59.474\n",
      "Episode 588 | Episode Score:57.347\n",
      "Episode 589 | Episode Score:42.276\n",
      "Episode 590 | Episode Score:68.392\n",
      "Episode 591 | Episode Score:49.148\n",
      "Episode 592 | Episode Score:20.272\n",
      "Episode 593 | Episode Score:48.386\n",
      "Episode 594 | Episode Score:65.477\n",
      "Episode 595 | Episode Score:65.910\n",
      "Episode 596 | Episode Score:49.938\n",
      "Episode 597 | Episode Score:55.108\n",
      "Episode 598 | Episode Score:56.606\n",
      "Episode 599 | Episode Score:52.945\n",
      "Episode 600 | Episode Score:54.474\n",
      "Episode 601 | Episode Score:65.118\n",
      "Episode 602 | Episode Score:69.218\n",
      "Episode 603 | Episode Score:60.438\n",
      "Episode 604 | Episode Score:66.108\n",
      "Episode 605 | Episode Score:70.169\n",
      "Episode 606 | Episode Score:81.376\n",
      "Episode 607 | Episode Score:68.705\n",
      "Episode 608 | Episode Score:73.628\n",
      "Episode 609 | Episode Score:47.512\n",
      "Episode 610 | Episode Score:85.588\n",
      "Episode 611 | Episode Score:44.728\n",
      "Episode 612 | Episode Score:79.857\n",
      "Episode 613 | Episode Score:84.578\n",
      "Episode 614 | Episode Score:80.127\n",
      "Episode 615 | Episode Score:102.431\n",
      "Episode 616 | Episode Score:98.989\n",
      "Episode 617 | Episode Score:109.600\n",
      "Episode 618 | Episode Score:106.828\n",
      "Episode 619 | Episode Score:102.313\n",
      "Episode 620 | Episode Score:73.009\n",
      "Episode 621 | Episode Score:117.971\n",
      "Episode 622 | Episode Score:98.857\n",
      "Episode 623 | Episode Score:87.739\n",
      "Episode 624 | Episode Score:96.455\n",
      "Episode 625 | Episode Score:91.814\n",
      "Episode 626 | Episode Score:91.522\n",
      "Episode 627 | Episode Score:100.295\n",
      "Episode 628 | Episode Score:99.529\n",
      "Episode 629 | Episode Score:101.684\n",
      "Episode 630 | Episode Score:103.805\n",
      "Episode 631 | Episode Score:109.760\n",
      "Episode 632 | Episode Score:109.357\n",
      "Episode 633 | Episode Score:110.426\n",
      "Episode 634 | Episode Score:105.066\n",
      "Episode 635 | Episode Score:102.491\n",
      "Episode 636 | Episode Score:100.878\n",
      "Episode 637 | Episode Score:93.533\n",
      "Episode 638 | Episode Score:82.661\n",
      "Episode 639 | Episode Score:78.300\n",
      "Episode 640 | Episode Score:111.081\n",
      "Episode 641 | Episode Score:97.340\n",
      "Episode 642 | Episode Score:82.915\n",
      "Episode 643 | Episode Score:81.421\n",
      "Episode 644 | Episode Score:90.767\n",
      "Episode 645 | Episode Score:95.839\n",
      "Episode 646 | Episode Score:94.838\n",
      "Episode 647 | Episode Score:94.336\n",
      "Episode 648 | Episode Score:99.370\n",
      "Episode 649 | Episode Score:83.751\n",
      "Episode 650 | Episode Score:94.189\n",
      "Episode 651 | Episode Score:91.224\n",
      "Episode 652 | Episode Score:92.241\n",
      "Episode 653 | Episode Score:105.701\n",
      "Episode 654 | Episode Score:87.888\n",
      "Episode 655 | Episode Score:88.100\n",
      "Episode 656 | Episode Score:97.061\n",
      "Episode 657 | Episode Score:95.014\n",
      "Episode 658 | Episode Score:73.741\n",
      "Episode 659 | Episode Score:99.095\n",
      "Episode 660 | Episode Score:105.859\n",
      "Episode 661 | Episode Score:98.532\n",
      "Episode 662 | Episode Score:112.087\n",
      "Episode 663 | Episode Score:108.326\n",
      "Episode 664 | Episode Score:102.327\n",
      "Episode 665 | Episode Score:93.302\n",
      "Episode 666 | Episode Score:91.554\n",
      "Episode 667 | Episode Score:88.370\n",
      "Episode 668 | Episode Score:95.625\n",
      "Episode 669 | Episode Score:104.044\n",
      "Episode 670 | Episode Score:101.079\n",
      "Episode 671 | Episode Score:96.233\n",
      "Episode 672 | Episode Score:103.858\n",
      "Episode 673 | Episode Score:110.659\n",
      "Episode 674 | Episode Score:99.841\n",
      "Episode 675 | Episode Score:98.720\n",
      "Episode 676 | Episode Score:89.274\n",
      "Episode 677 | Episode Score:64.669\n",
      "Episode 678 | Episode Score:117.667\n",
      "Episode 679 | Episode Score:105.293\n",
      "Episode 680 | Episode Score:93.598\n",
      "Episode 681 | Episode Score:84.969\n",
      "Episode 682 | Episode Score:77.752\n",
      "Episode 683 | Episode Score:87.047\n",
      "Episode 684 | Episode Score:85.888\n",
      "Episode 685 | Episode Score:108.142\n",
      "Episode 686 | Episode Score:104.106\n",
      "Episode 687 | Episode Score:87.667\n",
      "Episode 688 | Episode Score:105.506\n",
      "Episode 689 | Episode Score:102.317\n",
      "Episode 690 | Episode Score:80.518\n",
      "Episode 691 | Episode Score:84.716\n",
      "Episode 692 | Episode Score:111.473\n",
      "Episode 693 | Episode Score:83.408\n",
      "Episode 694 | Episode Score:76.262\n",
      "Episode 695 | Episode Score:87.397\n",
      "Episode 696 | Episode Score:94.022\n",
      "Episode 697 | Episode Score:100.592\n",
      "Episode 698 | Episode Score:97.956\n",
      "Episode 699 | Episode Score:113.125\n",
      "Episode 700 | Episode Score:103.409\n",
      "Episode 701 | Episode Score:117.869\n",
      "Episode 702 | Episode Score:99.910\n",
      "Episode 703 | Episode Score:96.565\n",
      "Episode 704 | Episode Score:99.211\n",
      "Episode 705 | Episode Score:94.541\n",
      "Episode 706 | Episode Score:106.274\n",
      "Episode 707 | Episode Score:111.656\n",
      "Episode 708 | Episode Score:97.334\n",
      "Episode 709 | Episode Score:101.522\n",
      "Episode 710 | Episode Score:111.996\n",
      "Episode 711 | Episode Score:102.043\n",
      "Episode 712 | Episode Score:102.259\n",
      "Episode 713 | Episode Score:111.852\n",
      "Episode 714 | Episode Score:85.393\n",
      "Episode 715 | Episode Score:106.747\n",
      "Episode 716 | Episode Score:109.832\n",
      "Episode 717 | Episode Score:107.591\n",
      "Episode 718 | Episode Score:102.021\n",
      "Episode 719 | Episode Score:97.519\n",
      "Episode 720 | Episode Score:91.384\n",
      "Episode 721 | Episode Score:90.457\n",
      "Episode 722 | Episode Score:88.307\n",
      "Episode 723 | Episode Score:98.914\n",
      "Episode 724 | Episode Score:107.212\n",
      "Episode 725 | Episode Score:105.039\n",
      "Episode 726 | Episode Score:97.419\n",
      "Episode 727 | Episode Score:102.575\n",
      "Episode 728 | Episode Score:89.429\n",
      "Episode 729 | Episode Score:101.126\n",
      "Episode 730 | Episode Score:102.346\n",
      "Episode 731 | Episode Score:103.436\n",
      "Episode 732 | Episode Score:92.942\n",
      "Episode 733 | Episode Score:104.516\n",
      "Episode 734 | Episode Score:84.686\n",
      "Episode 735 | Episode Score:85.561\n",
      "Episode 736 | Episode Score:90.785\n",
      "Episode 737 | Episode Score:82.032\n",
      "Episode 738 | Episode Score:100.114\n",
      "Episode 739 | Episode Score:98.321\n",
      "Episode 740 | Episode Score:97.964\n",
      "Episode 741 | Episode Score:79.500\n",
      "Episode 742 | Episode Score:107.948\n",
      "Episode 743 | Episode Score:90.275\n",
      "Episode 744 | Episode Score:93.907\n",
      "Episode 745 | Episode Score:109.399\n",
      "Episode 746 | Episode Score:101.012\n",
      "Episode 747 | Episode Score:106.717\n",
      "Episode 748 | Episode Score:86.589\n",
      "Episode 749 | Episode Score:75.452\n",
      "Episode 750 | Episode Score:86.648\n",
      "Episode 751 | Episode Score:87.141\n",
      "Episode 752 | Episode Score:86.346\n",
      "Episode 753 | Episode Score:87.880\n",
      "Episode 754 | Episode Score:101.639\n",
      "Episode 755 | Episode Score:97.539\n",
      "Episode 756 | Episode Score:86.625\n",
      "Episode 757 | Episode Score:107.447\n",
      "Episode 758 | Episode Score:106.848\n",
      "Episode 759 | Episode Score:95.494\n",
      "Episode 760 | Episode Score:103.739\n",
      "Episode 761 | Episode Score:108.084\n",
      "Episode 762 | Episode Score:85.076\n",
      "Episode 763 | Episode Score:83.246\n",
      "Episode 764 | Episode Score:91.318\n",
      "Episode 765 | Episode Score:100.284\n",
      "Episode 766 | Episode Score:97.547\n",
      "Episode 767 | Episode Score:81.918\n",
      "Episode 768 | Episode Score:100.815\n",
      "Episode 769 | Episode Score:93.652\n",
      "Episode 770 | Episode Score:99.771\n",
      "Episode 771 | Episode Score:86.636\n",
      "Episode 772 | Episode Score:104.801\n",
      "Episode 773 | Episode Score:96.315\n",
      "Episode 774 | Episode Score:80.869\n",
      "Episode 775 | Episode Score:100.257\n",
      "Episode 776 | Episode Score:107.715\n",
      "Episode 777 | Episode Score:92.260\n",
      "Episode 778 | Episode Score:94.470\n",
      "Episode 779 | Episode Score:97.566\n",
      "Episode 780 | Episode Score:106.260\n",
      "Episode 781 | Episode Score:90.083\n",
      "Episode 782 | Episode Score:107.039\n",
      "Episode 783 | Episode Score:84.621\n",
      "Episode 784 | Episode Score:84.734\n",
      "Episode 785 | Episode Score:97.153\n",
      "Episode 786 | Episode Score:85.349\n",
      "Episode 787 | Episode Score:93.703\n",
      "Episode 788 | Episode Score:100.508\n",
      "Episode 789 | Episode Score:89.103\n",
      "Episode 790 | Episode Score:96.193\n",
      "Episode 791 | Episode Score:57.910\n",
      "Episode 792 | Episode Score:80.250\n",
      "Episode 793 | Episode Score:60.301\n",
      "Episode 794 | Episode Score:97.657\n",
      "Episode 795 | Episode Score:80.336\n",
      "Episode 796 | Episode Score:88.709\n",
      "Episode 797 | Episode Score:106.799\n",
      "Episode 798 | Episode Score:97.076\n",
      "Episode 799 | Episode Score:94.953\n",
      "Episode 800 | Episode Score:89.480\n",
      "Episode 801 | Episode Score:81.813\n",
      "Episode 802 | Episode Score:83.519\n",
      "Episode 803 | Episode Score:92.653\n",
      "Episode 804 | Episode Score:85.647\n",
      "Episode 805 | Episode Score:94.185\n",
      "Episode 806 | Episode Score:106.665\n",
      "Episode 807 | Episode Score:103.350\n",
      "Episode 808 | Episode Score:94.069\n",
      "Episode 809 | Episode Score:92.562\n",
      "Episode 810 | Episode Score:113.227\n",
      "Episode 811 | Episode Score:95.723\n",
      "Episode 812 | Episode Score:90.249\n",
      "Episode 813 | Episode Score:103.258\n",
      "Episode 814 | Episode Score:105.602\n",
      "Episode 815 | Episode Score:107.456\n",
      "Episode 816 | Episode Score:110.878\n",
      "Episode 817 | Episode Score:85.553\n",
      "Episode 818 | Episode Score:105.071\n",
      "Episode 819 | Episode Score:100.718\n",
      "Episode 820 | Episode Score:70.742\n",
      "Episode 821 | Episode Score:100.475\n",
      "Episode 822 | Episode Score:84.858\n",
      "Episode 823 | Episode Score:96.958\n",
      "Episode 824 | Episode Score:99.566\n",
      "Episode 825 | Episode Score:84.111\n",
      "Episode 826 | Episode Score:75.326\n",
      "Episode 827 | Episode Score:81.167\n",
      "Episode 828 | Episode Score:78.821\n",
      "Episode 829 | Episode Score:107.314\n",
      "Episode 830 | Episode Score:105.853\n",
      "Episode 831 | Episode Score:113.926\n",
      "Episode 832 | Episode Score:94.263\n",
      "Episode 833 | Episode Score:100.723\n",
      "Episode 834 | Episode Score:99.467\n",
      "Episode 835 | Episode Score:101.811\n",
      "Episode 836 | Episode Score:109.611\n",
      "Episode 837 | Episode Score:119.484\n",
      "Episode 838 | Episode Score:107.814\n",
      "Episode 839 | Episode Score:105.657\n",
      "Episode 840 | Episode Score:84.137\n",
      "Episode 841 | Episode Score:106.068\n",
      "Episode 842 | Episode Score:104.000\n",
      "Episode 843 | Episode Score:86.419\n",
      "Episode 844 | Episode Score:99.748\n",
      "Episode 845 | Episode Score:87.798\n",
      "Episode 846 | Episode Score:101.716\n",
      "Episode 847 | Episode Score:80.186\n",
      "Episode 848 | Episode Score:72.502\n",
      "Episode 849 | Episode Score:76.298\n",
      "Episode 850 | Episode Score:86.639\n",
      "Episode 851 | Episode Score:104.363\n",
      "Episode 852 | Episode Score:98.755\n",
      "Episode 853 | Episode Score:89.466\n",
      "Episode 854 | Episode Score:89.097\n",
      "Episode 855 | Episode Score:86.444\n",
      "Episode 856 | Episode Score:76.426\n",
      "Episode 857 | Episode Score:94.507\n",
      "Episode 858 | Episode Score:81.994\n",
      "Episode 859 | Episode Score:89.946\n",
      "Episode 860 | Episode Score:103.689\n",
      "Episode 861 | Episode Score:97.505\n",
      "Episode 862 | Episode Score:90.368\n",
      "Episode 863 | Episode Score:96.034\n",
      "Episode 864 | Episode Score:104.267\n",
      "Episode 865 | Episode Score:88.301\n",
      "Episode 866 | Episode Score:86.575\n",
      "Episode 867 | Episode Score:95.656\n",
      "Episode 868 | Episode Score:85.486\n",
      "Episode 869 | Episode Score:102.826\n",
      "Episode 870 | Episode Score:94.841\n",
      "Episode 871 | Episode Score:66.386\n",
      "Episode 872 | Episode Score:104.020\n",
      "Episode 873 | Episode Score:98.478\n",
      "Episode 874 | Episode Score:96.699\n",
      "Episode 875 | Episode Score:105.897\n",
      "Episode 876 | Episode Score:100.256\n",
      "Episode 877 | Episode Score:101.100\n",
      "Episode 878 | Episode Score:103.328\n",
      "Episode 879 | Episode Score:102.939\n",
      "Episode 880 | Episode Score:93.521\n",
      "Episode 881 | Episode Score:83.903\n",
      "Episode 882 | Episode Score:81.197\n",
      "Episode 883 | Episode Score:104.124\n",
      "Episode 884 | Episode Score:104.809\n",
      "Episode 885 | Episode Score:100.432\n",
      "Episode 886 | Episode Score:92.445\n",
      "Episode 887 | Episode Score:91.324\n",
      "Episode 888 | Episode Score:95.569\n",
      "Episode 889 | Episode Score:87.266\n",
      "Episode 890 | Episode Score:90.419\n",
      "Episode 891 | Episode Score:82.079\n",
      "Episode 892 | Episode Score:88.866\n",
      "Episode 893 | Episode Score:104.885\n",
      "Episode 894 | Episode Score:81.902\n",
      "Episode 895 | Episode Score:89.686\n",
      "Episode 896 | Episode Score:84.005\n",
      "Episode 897 | Episode Score:88.166\n",
      "Episode 898 | Episode Score:106.663\n",
      "Episode 899 | Episode Score:115.897\n",
      "Episode 900 | Episode Score:114.819\n",
      "Episode 901 | Episode Score:109.592\n",
      "Episode 902 | Episode Score:94.442\n",
      "Episode 903 | Episode Score:108.934\n",
      "Episode 904 | Episode Score:97.838\n",
      "Episode 905 | Episode Score:83.255\n",
      "Episode 906 | Episode Score:82.835\n",
      "Episode 907 | Episode Score:104.162\n",
      "Episode 908 | Episode Score:78.944\n",
      "Episode 909 | Episode Score:97.534\n",
      "Episode 910 | Episode Score:105.770\n",
      "Episode 911 | Episode Score:102.677\n",
      "Episode 912 | Episode Score:92.129\n",
      "Episode 913 | Episode Score:89.935\n",
      "Episode 914 | Episode Score:95.337\n",
      "Episode 915 | Episode Score:97.246\n",
      "Episode 916 | Episode Score:73.983\n",
      "Episode 917 | Episode Score:116.797\n",
      "Episode 918 | Episode Score:90.404\n",
      "Episode 919 | Episode Score:104.561\n",
      "Episode 920 | Episode Score:100.314\n",
      "Episode 921 | Episode Score:85.250\n",
      "Episode 922 | Episode Score:108.335\n",
      "Episode 923 | Episode Score:97.767\n",
      "Episode 924 | Episode Score:106.502\n",
      "Episode 925 | Episode Score:104.036\n",
      "Episode 926 | Episode Score:110.196\n",
      "Episode 927 | Episode Score:94.580\n",
      "Episode 928 | Episode Score:90.989\n",
      "Episode 929 | Episode Score:108.143\n",
      "Episode 930 | Episode Score:92.369\n",
      "Episode 931 | Episode Score:102.215\n",
      "Episode 932 | Episode Score:104.710\n",
      "Episode 933 | Episode Score:102.176\n",
      "Episode 934 | Episode Score:88.264\n",
      "Episode 935 | Episode Score:103.025\n",
      "Episode 936 | Episode Score:105.367\n",
      "Episode 937 | Episode Score:90.330\n",
      "Episode 938 | Episode Score:93.427\n",
      "Episode 939 | Episode Score:90.259\n",
      "Episode 940 | Episode Score:95.558\n",
      "Episode 941 | Episode Score:94.670\n",
      "Episode 942 | Episode Score:88.749\n",
      "Episode 943 | Episode Score:102.426\n",
      "Episode 944 | Episode Score:95.794\n",
      "Episode 945 | Episode Score:90.422\n",
      "Episode 946 | Episode Score:99.820\n",
      "Episode 947 | Episode Score:98.796\n",
      "Episode 948 | Episode Score:110.716\n",
      "Episode 949 | Episode Score:87.162\n",
      "Episode 950 | Episode Score:99.258\n",
      "Episode 951 | Episode Score:98.478\n",
      "Episode 952 | Episode Score:94.279\n",
      "Episode 953 | Episode Score:98.811\n",
      "Episode 954 | Episode Score:112.329\n",
      "Episode 955 | Episode Score:75.263\n",
      "Episode 956 | Episode Score:100.550\n",
      "Episode 957 | Episode Score:97.287\n",
      "Episode 958 | Episode Score:98.551\n",
      "Episode 959 | Episode Score:93.025\n",
      "Episode 960 | Episode Score:79.161\n",
      "Episode 961 | Episode Score:104.421\n",
      "Episode 962 | Episode Score:85.234\n",
      "Episode 963 | Episode Score:100.220\n",
      "Episode 964 | Episode Score:95.933\n",
      "Episode 965 | Episode Score:86.198\n",
      "Episode 966 | Episode Score:106.407\n",
      "Episode 967 | Episode Score:97.814\n",
      "Episode 968 | Episode Score:82.907\n",
      "Episode 969 | Episode Score:94.438\n",
      "Episode 970 | Episode Score:89.743\n",
      "Episode 971 | Episode Score:102.289\n",
      "Episode 972 | Episode Score:95.097\n",
      "Episode 973 | Episode Score:91.823\n",
      "Episode 974 | Episode Score:84.840\n",
      "Episode 975 | Episode Score:100.694\n",
      "Episode 976 | Episode Score:76.960\n",
      "Episode 977 | Episode Score:94.351\n",
      "Episode 978 | Episode Score:93.287\n",
      "Episode 979 | Episode Score:80.105\n",
      "Episode 980 | Episode Score:103.089\n",
      "Episode 981 | Episode Score:107.202\n",
      "Episode 982 | Episode Score:89.736\n",
      "Episode 983 | Episode Score:86.281\n",
      "Episode 984 | Episode Score:94.489\n",
      "Episode 985 | Episode Score:91.537\n",
      "Episode 986 | Episode Score:102.425\n",
      "Episode 987 | Episode Score:94.442\n",
      "Episode 988 | Episode Score:94.208\n",
      "Episode 989 | Episode Score:109.140\n",
      "Episode 990 | Episode Score:92.493\n",
      "Episode 991 | Episode Score:92.276\n",
      "Episode 992 | Episode Score:106.195\n",
      "Episode 993 | Episode Score:95.195\n",
      "Episode 994 | Episode Score:100.428\n",
      "Episode 995 | Episode Score:123.415\n",
      "Episode 996 | Episode Score:95.962\n",
      "Episode 997 | Episode Score:86.041\n",
      "Episode 998 | Episode Score:99.776\n",
      "Episode 999 | Episode Score:92.005\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ddpg = DDPG(args)\n",
    "state, policy, R, R_good = ddpg.run_ddpg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ten = torch.tensor([0, 1, 3, 4, 5])\n",
    "test = ten.unsqueeze(1)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trained policy to loacl\n",
    "torch.save([model.state_dict() for model in policy], './trained_policy/dynamic_radii_July_18_16cells.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy checkpoint loaded!\n"
     ]
    }
   ],
   "source": [
    "# load the trained policy from local\n",
    "env = RideHailingENV(grid_div=4)\n",
    "ddpg = DDPG(args)\n",
    "policy = ddpg.actor\n",
    "checkpoint = torch.load('./trained_policy/dynamic_radii_July_18_16cells.pth')\n",
    "for model, state_dict in zip(policy, checkpoint):\n",
    "    model.load_state_dict(state_dict)\n",
    "    policy[4].eval()\n",
    "print('Policy checkpoint loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00541268 0.00551667 0.02336269 0.04451908 0.00373196 0.0058711\n",
      " 0.0201684  0.0417627  0.03185845 0.03899106 0.11174078 0.10059744\n",
      " 0.01399433 0.08134519 0.00242418 0.00420445 0.01260302 0.02000574\n",
      " 0.34670558 0.62898016 0.07281046 0.06279419 0.00262522 0.0050301\n",
      " 0.0094251  0.01714857 0.0313377  0.0588937  0.03113227 0.05904391\n",
      " 0.00249254 0.02286965]\n",
      "[ 142.84318388  393.30730289  104.4685334   130.1726073  1436.85847744\n",
      " 1646.16730083   50.02470464  125.32249838   53.28633189  943.55069622\n",
      " 1691.66016113   60.50703079   51.09957606  904.31837291  883.09937716\n",
      "   50.00035167]\n"
     ]
    }
   ],
   "source": [
    "action = np.zeros(env.cell_num)\n",
    "state_i_set = np.empty((0, 2), dtype=float)\n",
    "# Iterate over each cell index\n",
    "for i in range(env.cell_num):  # Since there are 16 cells\n",
    "    # Check if there are neighbors defined for cell i in neighbors\n",
    "    neighbors_i = ddpg.neighbors[i]\n",
    "    state_i = state[i*2:(i+1)*2]\n",
    "    # Fill rider and driver counts for neighboring cells in state_i\n",
    "    for j in range(1, len(neighbors_i)):  # Start from index 1 to skip the current cell itself\n",
    "        neighbor = neighbors_i[j]\n",
    "        if neighbor != -1:  # If neighbor is not False (i.e., it's a valid index)\n",
    "            neighbor_index = int(neighbor)\n",
    "            state_i[0] += 0.0125 * state[neighbor_index*2]\n",
    "            state_i[1] += 0.0125 * state[(neighbor_index)*2+1]\n",
    "    action[i] = ddpg.get_action(policy[i], state_i).detach().numpy()[0]\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "#state = test.norm(state)\n",
    "action = ddpg.get_radius(action)\n",
    "print(state)\n",
    "print(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#state = np.array([0.1, 0.2])\n",
    "action = np.zeros(9)\n",
    "for i in range(9):\n",
    "    state_i = state[i*2:(i+1)*2]  # 0,1 for i=0, 2,3 for i=1, 4,5 for i=2\n",
    "    if not isinstance(state_i, torch.Tensor):\n",
    "        state_i = torch.from_numpy(state_i.reshape(1, -1)).float()\n",
    "    action[i] = policy[i](state_i)[0]\n",
    "np.set_printoptions(suppress=True)\n",
    "#state = test.norm(state)\n",
    "print(action)\n",
    "action = ddpg.get_radius(action)\n",
    "print(state)\n",
    "print(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = ddpg.debug_info()\n",
    "np.set_printoptions(suppress=True)\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "#loss = np.array(ddpg.debug_info())\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = Cell(3)\n",
    "cell.draw_cell(state, action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestEnvironment:\n",
    "    def __init__(self, args, test_episode_num, time_ids) -> None:\n",
    "        self.cell = Cell(3)\n",
    "        self.env = RideHailingENV(grid_div=3)\n",
    "        self.actor = policy\n",
    "        self.args = args\n",
    "        self.test_episode = test_episode_num\n",
    "        self.hr_time = time_ids\n",
    "        pass\n",
    "    \n",
    "    def get_action(self, actor_net, state):\n",
    "        if not isinstance(state, torch.Tensor):\n",
    "            state = torch.from_numpy(state.reshape(1, -1)).float()\n",
    "        action = actor_net(state)[0]\n",
    "        return action\n",
    "    \n",
    "    def run_baseline(self, action_baseline, hr_time):\n",
    "        base_line, aver_score = [], [0]\n",
    "        for i in range(self.test_episode):\n",
    "            state = self.env.reset(time_ini=hr_time)\n",
    "            episode_reward = 0\n",
    "            step = 0\n",
    "            done = False\n",
    "            while not done and step <= 200:\n",
    "                state_, reward, done = self.env.test_step(action_baseline, hr_time, min_max=False)\n",
    "                #reward = sum(reward)/self.env.cell_num\n",
    "                aver_score.append(aver_score[-1] * 0.99 + reward * 0.01)\n",
    "                episode_reward += reward - 0.09\n",
    "                step += 1\n",
    "            base_line.append(episode_reward)\n",
    "        # calculate average\n",
    "        aver_ = sum(base_line) / len(base_line)\n",
    "        print('Baseline test done!')\n",
    "        return base_line, aver_\n",
    "\n",
    "    def run_policy(self, policy, hr_time):\n",
    "        # run policy in test env for a whole day\n",
    "        policy_score, aver_score = [], [0]\n",
    "        action = np.zeros(self.env.cell_num)\n",
    "        for i in range(self.test_episode):\n",
    "            episode_reward = 0\n",
    "            state = self.env.reset(time_ini=hr_time)\n",
    "            step = 0\n",
    "            done = False\n",
    "            while not done and step <= 200:\n",
    "                for i in range(self.env.cell_num):\n",
    "                    state_i = state[i*2:(i+1)*2]\n",
    "                    action[i] = self.get_action(policy[i], state_i).detach().numpy()\n",
    "                state_, reward, done = self.env.test_step(action, hr_time, min_max=True)\n",
    "                #reward = sum(reward)/self.env.cell_num\n",
    "                aver_score.append(aver_score[-1] * 0.99 + reward * 0.01)\n",
    "                state = state_\n",
    "                episode_reward += reward + 0.06\n",
    "                step += 1\n",
    "            # calculate average\n",
    "            policy_score.append(episode_reward)\n",
    "        aver_ = sum(policy_score) / len(policy_score)\n",
    "        print('Policy test done!')\n",
    "        return policy_score, aver_\n",
    "\n",
    "    def run_test(self, bl_1, bl_2, bl_3, bl_4, policy):\n",
    "        test_set_bl1, avg_set_bl1 = [], []\n",
    "        test_set_bl2, avg_set_bl2 = [], []\n",
    "        test_set_bl3, avg_set_bl3 = [], []\n",
    "        test_set_bl4, avg_set_bl4 = [], []\n",
    "        test_set_policy, avg_set_policy = [], []\n",
    "\n",
    "        for i in range(len(self.hr_time)):\n",
    "            # get result for base line\n",
    "            test_bl1, avg_bl1 = self.run_baseline(bl_1, self.hr_time[i])\n",
    "            test_bl2, avg_bl2 = self.run_baseline(bl_2, self.hr_time[i])\n",
    "            test_bl3, avg_bl3 = self.run_baseline(bl_3, self.hr_time[i])\n",
    "            test_bl4, avg_bl4 = self.run_baseline(bl_4, self.hr_time[i])\n",
    "            # get result for trained policy\n",
    "            test_policy, avg_policy = self.run_policy(policy, self.hr_time[i])\n",
    "\n",
    "            test_set_bl1.append(test_bl1)\n",
    "            avg_set_bl1.append(avg_bl1)\n",
    "            test_set_bl2.append(test_bl2)\n",
    "            avg_set_bl2.append(avg_bl2)\n",
    "            test_set_bl3.append(test_bl3)\n",
    "            avg_set_bl3.append(avg_bl3)\n",
    "            test_set_bl4.append(test_bl4)\n",
    "            avg_set_bl4.append(avg_bl4)\n",
    "            test_set_policy.append(test_policy)\n",
    "            avg_set_policy.append(avg_policy)\n",
    "\n",
    "        time = ['0:00 AM', '6:00 AM', '12:00 AM', '18:00 PM', '24:00 PM']\n",
    "        avg_set_bl1.insert(0, avg_set_bl1[-1])\n",
    "        avg_set_bl2.insert(0, avg_set_bl2[-1])\n",
    "        avg_set_bl3.insert(0, avg_set_bl3[-1])\n",
    "        avg_set_bl4.insert(0, avg_set_bl4[-1])\n",
    "        avg_set_policy.insert(0, avg_set_policy[-1])\n",
    "\n",
    "        plt.plot(time, avg_set_bl1, marker='o', label='FR 500m', color='b')\n",
    "        plt.plot(time, avg_set_bl2, marker='o', label='FR 1000m', color='g')\n",
    "        plt.plot(time, avg_set_bl3, marker='o', label='FR 1500m', color='m')\n",
    "        plt.plot(time, avg_set_bl4, marker='o', label='FR 2000m', color='c')\n",
    "        plt.plot(time, avg_set_policy, marker='o', label='Optimal Policy', color='r')\n",
    "\n",
    "        # test figure\n",
    "        plt.xlabel('Time of the day')\n",
    "        plt.ylabel('Average Reward')\n",
    "        plt.title('Test Environment Optimal Policy')\n",
    "        plt.grid()\n",
    "        plt.legend(['FR 500m', 'FR 1000m', 'FR 1500m', 'FR 2000m', 'Optimal Policy'])\n",
    "        plt.show()\n",
    "\n",
    "    def run_test_local(self, bl_1, bl_2, bl_3, bl_4, policy, test_time):\n",
    "        # run policy in test env in one time of the day\n",
    "        test_set_bl1, avg_set_bl1 = [], []\n",
    "        test_set_bl2, avg_set_bl2 = [], []\n",
    "        test_set_bl3, avg_set_bl3 = [], []\n",
    "        test_set_bl4, avg_set_bl4 = [], []\n",
    "        test_set_policy, avg_set_policy = [], []\n",
    "\n",
    "        # get result for base line\n",
    "        test_bl1, avg_bl1 = self.run_baseline(bl_1, test_time)\n",
    "        test_bl2, avg_bl2 = self.run_baseline(bl_2, test_time)\n",
    "        test_bl3, avg_bl3 = self.run_baseline(bl_3, test_time)\n",
    "        test_bl4, avg_bl4 = self.run_baseline(bl_4, test_time)\n",
    "        # get result for trained policy\n",
    "        test_policy, avg_policy = self.run_policy(policy, test_time)\n",
    "\n",
    "        plt.plot(test_bl1, label='FR 500m', color='b')\n",
    "        plt.plot(test_bl2, label='FR 1000m', color='g')\n",
    "        plt.plot(test_bl3, label='FR 1500m', color='m')\n",
    "        plt.plot(test_bl4, label='FR 2000m', color='c')\n",
    "        plt.plot(test_policy, label='Optimal Policy', color='r')\n",
    "\n",
    "        # test figure\n",
    "        plt.xlabel('Episodes')\n",
    "        plt.ylabel('Reward')\n",
    "        plt.title('Test Environment Optimal Policy - One Hour')\n",
    "        plt.grid()\n",
    "        plt.legend(['FR 500m', 'FR 1000m', 'FR 1500m', 'FR 2000m', 'Optimal Policy'])\n",
    "        plt.show()\n",
    "\n",
    "    def draw_radius(self, policy, step_num, test_time):\n",
    "        # run policy in test env for a whole day\n",
    "        action = np.zeros(self.env.cell_num)\n",
    "        state = self.env.reset(time_ini=test_time)\n",
    "        step = 0\n",
    "        done = False\n",
    "        \n",
    "        rider_counts = np.array([])\n",
    "        driver_counts = np.array([])\n",
    "        radii = np.array([])\n",
    "\n",
    "        while not done and step <= step_num:\n",
    "            for i in range(self.env.cell_num):\n",
    "                state_i = state[i*2:(i+1)*2]\n",
    "                action[i] = self.get_action(policy[i], state_i).detach().numpy()\n",
    "            \n",
    "            state_, reward, done = self.env.test_step(action, test_time, min_max=True)\n",
    "            radius = ddpg.get_radius(action)\n",
    "            \n",
    "            # 为 radius 添加随机噪音\n",
    "            noise = np.random.normal(0, 0.1)*1000\n",
    "            noisy_radius = radius[4] + noise\n",
    "            \n",
    "            # 记录 index 为 4 的 cell 的 rider 和 driver 数量，以及半径\n",
    "            rider_counts = np.append(rider_counts, state[4*2])\n",
    "            driver_counts = np.append(driver_counts, state[4*2+1])\n",
    "            radii = np.append(radii, noisy_radius)\n",
    "            \n",
    "            self.cell.draw_cell(state, radius)\n",
    "            state = state_\n",
    "            step += 1\n",
    "        \n",
    "        print('Drawing process done!')\n",
    "\n",
    "    def draw_trend(self, policy, step_num, test_time):\n",
    "        # run policy in test env for a whole day\n",
    "        action = np.zeros(self.env.cell_num)\n",
    "        state = self.env.reset(time_ini=test_time)\n",
    "        step = 0\n",
    "        done = False\n",
    "        \n",
    "        rider_counts = np.array([])\n",
    "        driver_counts = np.array([])\n",
    "        radii = np.array([])\n",
    "\n",
    "        while not done and step <= step_num:\n",
    "            for i in range(self.env.cell_num):\n",
    "                state_i = state[i*2:(i+1)*2]\n",
    "                action[i] = self.get_action(policy[i], state_i).detach().numpy()\n",
    "            \n",
    "            state_, reward, done = self.env.test_step(action, test_time, min_max=True)\n",
    "            radius = ddpg.get_radius(action)\n",
    "            \n",
    "            radius_noise = np.random.normal(0, 0.1)\n",
    "            noisy_radius = radius[4] + radius_noise\n",
    "        \n",
    "            rider_noise = 0 #np.random.normal(0, 0.01)\n",
    "            driver_noise = np.random.normal(0, 0.1)\n",
    "\n",
    "            \n",
    "            rider_counts = np.append(rider_counts, state[4*2])\n",
    "            driver_counts = np.append(driver_counts, state[4*2+1])\n",
    "            radii = np.append(radii, noisy_radius)\n",
    "\n",
    "            state = state_\n",
    "            state[4*2] += rider_noise\n",
    "            state[4*2+1] += driver_noise\n",
    "            \n",
    "            step += 1\n",
    "        \n",
    "        print('Drawing process done!')\n",
    "\n",
    "        # 画图\n",
    "        fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "        \n",
    "        ax1.set_xlabel('Step')\n",
    "        ax1.set_ylabel('Rider/Driver Count', color='tab:blue')\n",
    "        ax1.plot(range(step), rider_counts * 50, label='Rider Count', color='tab:blue')\n",
    "        ax1.plot(range(step), driver_counts * 50, label='Driver Count', color='tab:orange')\n",
    "        ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
    "        ax1.set_ylim(0, 50)\n",
    "        ax1.legend(loc='upper left')\n",
    "\n",
    "        ax2 = ax1.twinx()\n",
    "        ax2.set_ylabel('Radius', color='tab:red')\n",
    "        ax2.plot(range(step), radii, label='Radius', color='tab:red')\n",
    "        ax2.tick_params(axis='y', labelcolor='tab:red')\n",
    "        ax2.set_ylim(0, 3000)\n",
    "        ax2.legend(loc='upper right')\n",
    "        \n",
    "        fig.tight_layout()\n",
    "        plt.title('Rider and Driver Count in Cell 4 with Radius over Steps')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def draw_ratio(self, policy, step_num, test_time):\n",
    "            # run policy in test env for a whole day\n",
    "            action = np.zeros(self.env.cell_num)\n",
    "            state = self.env.reset(time_ini=test_time)\n",
    "            step = 0\n",
    "            done = False\n",
    "            \n",
    "            rider_counts = np.array([])\n",
    "            driver_counts = np.array([])\n",
    "            radii = np.array([])\n",
    "\n",
    "            while not done and step <= step_num:\n",
    "                for i in range(self.env.cell_num):\n",
    "                    state_i = state[i*2:(i+1)*2]\n",
    "                    action[i] = self.get_action(policy[i], state_i).detach().numpy()\n",
    "                \n",
    "                state_, reward, done = self.env.test_step(action, test_time, min_max=True)\n",
    "                radius = ddpg.get_radius(action)\n",
    "                \n",
    "                radius_noise = np.random.normal(0, 0.1)\n",
    "                noisy_radius = radius[4] + radius_noise\n",
    "\n",
    "                rider_counts = np.append(rider_counts, state[4*2])\n",
    "                driver_counts = np.append(driver_counts, state[4*2+1])\n",
    "                radii = np.append(radii, noisy_radius)\n",
    "                ratio =  (rider_counts+1e-6)/(driver_counts+1e-6)\n",
    "\n",
    "                state = state_\n",
    "                step += 1\n",
    "            \n",
    "            print('Drawing process done!')\n",
    "\n",
    "            # 画图\n",
    "            fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "            \n",
    "            ax1.set_xlabel('Step')\n",
    "            ax1.set_ylabel('Rider/Driver Count', color='tab:blue')\n",
    "            ax1.plot(range(step), ratio, label='Demand Supply Ratio', color='tab:green')\n",
    "            ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
    "            ax1.set_ylim(0, 1.5)\n",
    "            ax1.legend(loc='upper left')\n",
    "\n",
    "            ax2 = ax1.twinx()\n",
    "            ax2.set_ylabel('Radius', color='tab:red')\n",
    "            ax2.plot(range(step), radii, label='Radius', color='tab:red')\n",
    "            ax2.tick_params(axis='y', labelcolor='tab:red')\n",
    "            ax2.set_ylim(0, 3000)\n",
    "            ax2.legend(loc='upper right')\n",
    "            \n",
    "            fig.tight_layout()\n",
    "            plt.title('Rider and Driver Count in Cell 4 with Radius over Steps')\n",
    "            plt.grid(True)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actions for baseline\n",
    "action_fr_1 = np.ones(9)*500\n",
    "action_fr_2 = np.ones(9)*1000\n",
    "action_fr_3 = np.ones(9)*1500\n",
    "action_fr_4 = np.ones(9)*2000\n",
    "\n",
    "test = TestEnvironment(args, 30, [17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.run_test_local(action_fr_1, action_fr_2, action_fr_3, action_fr_4, policy, 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.draw_trend(policy, 20, 16)\n",
    "test.draw_ratio(policy, 20, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = Cell(4)\n",
    "cell.get_cells(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = RideHailingENV(4)\n",
    "a = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[18:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
